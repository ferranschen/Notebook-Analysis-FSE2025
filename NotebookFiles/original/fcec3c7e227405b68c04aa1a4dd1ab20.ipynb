{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfcf79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"%logstop\\n%logstart -t -r -q ipython_command_log.py global\\n\\n#- IRONHACKS RESEARCH TRACKING CODE\\n#----------------------------------\\n# The following code is used to help our research team understand how you \\n# our notebook environment. We do not collect any personal information with\\n# the following code, it is used to measure when and how often you work on\\n# your submission files.\\n\\nimport os\\nfrom datetime import datetime\\nimport IPython.core.history as history\\n\\nha = history.HistoryAccessor()\\nha_tail = ha.get_tail(1)\\nha_cmd = next(ha_tail)\\nsession_id = str(ha_cmd[0])\\ncommand_id = str(ha_cmd[1])\\ntimestamp = datetime.utcnow().isoformat()\\nhistory_line = ','.join([session_id, command_id, timestamp]) + '\\\\n'\\nlogfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\\nlogfile.write(history_line)\\nlogfile.close()\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d150a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"#- INSTALL ADDITIONAL LIBRARIES IF REQUIRED\\n#------------------------------------------\\n# This is normally not required. The hub environment comes preinstaled with \\n# many packages that you can already use without setup. In case there is some\\n# other library you would like to use that isn't on the list you run this command\\n# once to install them.  If it is already installed this command has no effect.\\n!pip install google-cloud-bigquery\\n!pip install google-cloud-bigquery[pandas]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- IMPORT THE LIBRARIES YOU WILL USE\n",
    "#------------------------------------------\n",
    "# You only need to import packages one time per notebook session. To keep your\n",
    "# notebook clean and organized you can handle all imports at the top of your file.\n",
    "# The following are included for example purposed, feel free to modify or delete \n",
    "# anything in this section.\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rand\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef3a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGQUERY_PROJECT = 'ironhacks-data'\n",
    "bigquery_client = bigquery.Client(project=BIGQUERY_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query 1: overview of employment_data(week 41)\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.unemployment_data`\n",
    "ORDER BY week_number ASC;\n",
    "\"\"\"\n",
    "query_job = bigquery_client.query(query)\n",
    "overview = query_job.to_dataframe()\n",
    "overview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043adcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query 2: overview of important info from unemployment table\n",
    "query = \"\"\"\n",
    "SELECT uu_id, week_number, total_claims\n",
    "FROM `ironhacks-data.ironhacks_competition.unemployment_data` \n",
    "ORDER BY week_number ASC\n",
    "\"\"\"\n",
    "query_jobb = bigquery_client.query(query)\n",
    "employ = query_jobb.to_dataframe()\n",
    "print(employ.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa159213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query 3: overview of prediction list (week 41)\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.prediction_list`\n",
    "\"\"\"\n",
    "query_job = bigquery_client.query(query)\n",
    "predn = query_job.to_dataframe()\n",
    "predn.head()\n",
    "print(predn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([employ.week_number], [employ.total_claims],'bs')\n",
    "plt.title('Distribution of claims through week')\n",
    "plt.xlabel('Weeks')\n",
    "plt.ylabel('Total claims')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average number of claims/ rates of change/ estimated errors (week 30-37)\n",
    "employ['avg'] = (sum(employ['total_claims'])/len(employ['total_claims']))\n",
    "employ['error'] = ((employ['total_claims']-employ['avg'])/employ['avg'])\n",
    "employ['avgError'] = (employ['error']/len(employ['total_claims']))\n",
    "avgError = (employ['error']/len(employ['total_claims']))\n",
    "avgError = avgError.drop_duplicates()\n",
    "l = employ[['week_number','total_claims','avg','error','avgError']]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985819c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(overview['total_claims'])\n",
    "features = employ.drop(['uu_id'], axis=1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c7fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test sets, split first 20% data\n",
    "x_train, x_test, y_train,y_test = train_test_split(features, labels, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71078a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training Features Shape: {x_train.shape}')\n",
    "print(f'Testing Features Shape: {x_test.shape}')\n",
    "print(f'Training Labels Shape: {y_train.shape}')\n",
    "print(f'Testing Labels Shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c89120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
    "x = x_train\n",
    "y = y_train\n",
    "regressor.fit(x,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the decision tree from the regressor\n",
    "from sklearn import tree\n",
    "tree.plot_tree(regressor.estimators_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb8f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regressor.predict(x_test).astype(int)\n",
    "predictions = np.round(predictions,decimals = 0, out = None)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004cebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = abs(y_test - predictions)\n",
    "print(f'List of Errors: {errors}')\n",
    "print(f'Mean Absolute Error: {np.mean(errors)*10:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e5a87",
   "metadata": {},
   "source": [
    "as the mean absolute error is less than 10%, we could take prediction as final outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions, columns=['total_claims'])\n",
    "week44 = predn.join(df).iloc[:,[0,2,1]]\n",
    "print(week44)\n",
    "print(f'Total predicting number of unemployment claims of week 44: {sum(predictions):.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddcc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = week44.to_csv(\"submission_prediction_output.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae2f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regressor.predict(x_test).astype(int)\n",
    "predictions = np.round(predictions,decimals = 0, out = None)\n",
    "predictions = predictions + avgError\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132504ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regressor.predict(x_test).astype(int)\n",
    "predictions = np.round(predictions,decimals = 0, out = None)\n",
    "predictions = predictions + avgError^21\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c90401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average number of claims/ rates of change/ estimated errors (week 30-37)\n",
    "employ['avg'] = (sum(employ['total_claims'])/len(employ['total_claims']))\n",
    "employ['error'] = ((employ['total_claims']-employ['avg'])/employ['avg'])\n",
    "employ['avgError'] = (employ['error']/len(employ['total_claims']))\n",
    "avgError = (employ['error']/len(employ['total_claims']))\n",
    "avgError = avgError.drop_duplicates()\n",
    "avgError = avgError/len(avgError)\n",
    "l = employ[['week_number','total_claims','avg','error','avgError']]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f019c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regressor.predict(x_test).astype(int)\n",
    "predictions = np.round(predictions,decimals = 0, out = None)\n",
    "predictions = predictions + avgError\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b9afb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "predictions = regressor.predict(x_test).astype(int)\n",
    "predictions = np.round(predictions,decimals = 0, out = None)\n",
    "predictions = predictions*(1-avgError)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
