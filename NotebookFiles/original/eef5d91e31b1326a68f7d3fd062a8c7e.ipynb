{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e4bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"\\n#- INSTALL ADDITIONAL LIBRARIES IF REQUIRED\\n#------------------------------------------\\n# This is normally not required. The hub environment comes preinstaled with \\n# many packages that you can already use without setup. In case there is some\\n# other library you would like to use that isn't on the list you run this command\\n# once to install them.  If it is already installed this command has no effect.\\n!pip install db-dtypes\\n!python3 -m pip install pandas\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e38e6",
   "metadata": {},
   "source": [
    "- IMPORT THE LIBRARIES YOU WILL USE\n",
    "------------------------------------------\n",
    "You only need to import packages one time per notebook session. To keep your\n",
    "notebook clean and organized you can handle all imports at the top of your file.\n",
    "The following are included for example purposed, feel free to modify or delete \n",
    "anything in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be4a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics\n",
    "import statsmodels.api as sm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0bf77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"\\n#- INSTALL ADDITIONAL LIBRARIES IF REQUIRED\\n#------------------------------------------\\n# This is normally not required. The hub environment comes preinstaled with \\n# many packages that you can already use without setup. In case there is some\\n# other library you would like to use that isn't on the list you run this command\\n# once to install them.  If it is already installed this command has no effect.\\n!pip install db-dtypes\\n!python3 -m pip install pandas\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a3a4f",
   "metadata": {},
   "source": [
    "- IMPORT THE LIBRARIES YOU WILL USE\n",
    "------------------------------------------\n",
    "You only need to import packages one time per notebook session. To keep your\n",
    "notebook clean and organized you can handle all imports at the top of your file.\n",
    "The following are included for example purposed, feel free to modify or delete \n",
    "anything in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c044c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics\n",
    "import statsmodels.api as sm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc76ab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "- DEFINE YOUR CLASSES AND FUNCTIONS \n",
    "-----------------------------------\n",
    "This is not required, but is helpful in keeping your notebook organized. \n",
    "You can use the following cell or several cells to define your functions\n",
    "and classes to keep them separate from your analysis or results code.\n",
    "In general it useful to define your methods in a separate cell from where\n",
    "it is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d4e79",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def dataExplore(data):\n",
    "    '''\n",
    "    Explore dataframe\n",
    "    '''\n",
    "    print(\"# of observations: \", data.shape[0])\n",
    "    for col in data.columns:\n",
    "        if col in [\"uu_id\", \"timeperiod\", \"week_number\", \"countyfips\", \"tract\", \"tract_name\", \"date\"]:\n",
    "            print(\"# of %s: %s\" % (col, len(pd.unique(data[col]))))\n",
    "        else:\n",
    "            print(\"Unique value of %s: %s\" % (col, pd.unique(data[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f45b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataBalanceCheck(data):\n",
    "    '''\n",
    "    Check the balance of data frame\n",
    "    '''\n",
    "    unbalance_count = 0\n",
    "    print(\"# of observations in complete time series: \", len(pd.unique(data[\"week_number\"])))\n",
    "    for id in pd.unique(data[\"uu_id\"]):\n",
    "        if len(data[data[\"uu_id\"] == id]) <  len(pd.unique(data[\"week_number\"])):\n",
    "            print(id, len(data[data[\"uu_id\"] == id]))\n",
    "            unbalance_count += 1\n",
    "    print(\"% of tracts with incomplete time series: \", unbalance_count / len(pd.unique(data[\"uu_id\"]))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af1cc98",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def dataFillNa(data, value):\n",
    "    \"\"\"\n",
    "   fill NA with given value in the dataframe\n",
    "    \"\"\"\n",
    "    for col in data.columns:\n",
    "        if col in [\"uu_id\", \"timeperiod\", \"week_number\", \"countyfips\", \"tract\", \"tract_name\", \"date\"]:\n",
    "            pass\n",
    "        elif col in [\"top_category_employer1\", \"top_category_employer2\", \"top_category_employer3\"]:\n",
    "            data[col] = data[col].replace({'N/A':str(value)})\n",
    "        else:\n",
    "            data[col] = data[col].fillna(value)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb40001",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def dataIdentifyDWM(data):\n",
    "    '''\n",
    "    Input: # of week. Output: data for the first day, its month and week order in the month\n",
    "    '''\n",
    "    data[\"date\"] = pd.to_datetime(2022 * 1000 + (1+(data[\"week_number\"]-1)*7), format='%Y%j')\n",
    "    data[\"month\"] = pd.DatetimeIndex(data[\"date\"]).month\n",
    "    data[\"weekofmonth\"]= pd.to_numeric(data[\"date\"].dt.day/7)\n",
    "    data['weekofmonth'] = data['weekofmonth'].apply(lambda x: math.ceil(x))\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59987b9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def MSPE(s1, s2):\n",
    "    print(\"MSPE: \", sum((s1 - s2)**2)/len(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955aee09",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def MAPE(s1, s2):\n",
    "    print(\"MAPE: \", sum(abs(s1 - s2))/len(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97bec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain data using BigQuery\n",
    "BIGQUERY_PROJECT = 'ironhacks-data'\n",
    "bigquery_client = bigquery.Client(project=BIGQUERY_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "a.*,\n",
    "b.average_wage\n",
    "FROM \n",
    "(SELECT \n",
    "*\n",
    "FROM `ironhacks-data.ironhacks_competition.unemployment_data`) a\n",
    "JOIN `ironhacks-data.ironhacks_competition.wage_data` b \n",
    "ON a.uu_id=b.uu_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923ce9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bigquery_client.query(query)\n",
    "data = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6761092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_pred = \"\"\"\n",
    "SELECT * FROM `ironhacks-data.ironhacks_competition.prediction_list`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a10735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job_pred = bigquery_client.query(query_pred)\n",
    "data_pred_query= query_job_pred.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be63ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further check tracts with average_wage as Nan\n",
    "# I find three tracts with all average_wage as Nan. If I drop these tracts due to Nan value, they cannot be predicted\n",
    "for id in pd.unique(data[data['average_wage'].isna()][\"uu_id\"]):\n",
    "    print(id)\n",
    "    print(\"All value are nan?\", data[data['uu_id'] == id][\"average_wage\"].isnull().all())\n",
    "    print(\"Included in prediction list?\", len(data_pred_query[data_pred_query['uu_id'] == id]) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949585e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup the data before pre-treatment\n",
    "data_backup = data.copy()\n",
    "data_pred_query_backup = data_pred_query.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretreatment: convert week_number to month and week of month, to capture seasonality\n",
    "data = dataIdentifyDWM(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To balance the dataset as panel data\n",
    "data_balance = data.set_index('week_number')\n",
    "data_balance = data_balance.sort_index(ascending=False)\n",
    "data_balance = data_balance.set_index('uu_id',append=True)\n",
    "data_balance = data_balance[~data_balance.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d71744",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balance = data_balance.reset_index(level=['week_number'])\n",
    "data_balance = (data_balance.set_index('week_number',append=True).reindex(pd.MultiIndex.from_product([data_balance.index.unique(),\n",
    "                                                      range(data_balance.week_number.min(),data_balance.week_number.max()+1)],\n",
    "                                                     names=['uu_id','week_number'])).reset_index(level=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58220c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balance = data_balance.set_index('week_number',append=True)\n",
    "data_balance['total_claims'] = data_balance['total_claims'].fillna(0)\n",
    "data_balance['average_wage'] = data_balance['average_wage'].interpolate(method = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d177056",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balance = data_balance.reset_index(level=['uu_id', \"week_number\"])\n",
    "data_balance = dataIdentifyDWM(data_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBalanceCheck(data_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data clean up: convert NA to 0 for gender, race, education and top employer and recalculate unknown category\n",
    "# Based on the check of Nan in average_wage above, I also convert Nan to zero as well, but try models with and without \"average_wage\" variable\n",
    "data = dataFillNa(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d8c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to training and validaton sets\n",
    "train_week = max(pd.unique(data[\"week_number\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e950596",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data[\"week_number\"] < train_week]\n",
    "data_valid = data[data[\"week_number\"] >= train_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8970c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_x = data_train.drop(\"total_claims\",1)\n",
    "data_train_y = data_train[\"total_claims\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid_x = data_valid.drop(\"total_claims\",1)\n",
    "data_valid_y = data_valid[\"total_claims\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9dcb0",
   "metadata": {},
   "source": [
    "Also prepare it for balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccf92be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balance_train = data_balance[data_balance[\"week_number\"] < train_week]\n",
    "data_balance_valid = data_balance[data_balance[\"week_number\"] >= train_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balance_train_x = data_balance_train.drop(\"total_claims\",1)\n",
    "data_balance_train_y = data_balance_train[\"total_claims\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balance_valid_x = data_balance_valid.drop(\"total_claims\",1)\n",
    "data_balance_valid_y = data_balance_valid[\"total_claims\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76755901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 : Poisson regression with unbalanced data\n",
    "data_train_x_m1 = data_train_x[[\"week_number\",\"month\", \"weekofmonth\",  \"average_wage\"]]\n",
    "data_train_x_m1[\"month\"] = data_train_x_m1[\"month\"].astype(str)\n",
    "data_train_x_m1[\"weekofmonth\"] = data_train_x_m1[\"weekofmonth\"].astype(str)\n",
    "data_train_x_m1[\"week_number2\"] = data_train_x_m1[\"week_number\"]**2\n",
    "data_train_x_m1 = pd.get_dummies(data_train_x_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e042790",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid_x_m1 = data_valid_x[[\"week_number\",\"month\", \"weekofmonth\",  \"average_wage\"]]\n",
    "data_valid_x_m1[\"month\"] = data_valid_x_m1[\"month\"].astype(str)\n",
    "data_valid_x_m1[\"weekofmonth\"] = data_valid_x_m1[\"weekofmonth\"].astype(str)\n",
    "data_valid_x_m1[\"week_number2\"] = data_valid_x_m1[\"week_number\"]**2\n",
    "data_valid_x_m1 = pd.get_dummies(data_valid_x_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73101e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    data_valid_x_m1[\"month_\"+str(1+i)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee0bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    if i == 1:\n",
    "        pass\n",
    "    data_valid_x_m1[\"weekofmonth_\"+str(1+i)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da948fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "poission_model = sm.GLM(data_train_y.astype(int), data_train_x_m1.astype(float), family=sm.families.Poisson())\n",
    "result = poission_model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_estimate_m1 = result.predict(data_valid_x_m1.astype(float))\n",
    "MSPE(data_estimate_m1, data_valid_y)\n",
    "MAPE(data_estimate_m1, data_valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Poisson with balanced data\n",
    "data_balance_train_x_m1 = data_balance_train_x[[\"week_number\",\"month\", \"weekofmonth\",  \"average_wage\"]]\n",
    "data_balance_train_x_m1[\"month\"] = data_balance_train_x_m1[\"month\"].astype(str)\n",
    "data_balance_train_x_m1[\"weekofmonth\"] = data_balance_train_x_m1[\"weekofmonth\"].astype(str)\n",
    "data_balance_train_x_m1[\"week_number2\"] = data_balance_train_x_m1[\"week_number\"]**2\n",
    "data_balance_train_x_m1 = pd.get_dummies(data_balance_train_x_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461785d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balance_valid_x_m1 = data_balance_valid_x[[\"week_number\",\"month\", \"weekofmonth\",  \"average_wage\"]]\n",
    "data_balance_valid_x_m1[\"month\"] = data_balance_valid_x_m1[\"month\"].astype(str)\n",
    "data_balance_valid_x_m1[\"weekofmonth\"] = data_balance_valid_x_m1[\"weekofmonth\"].astype(str)\n",
    "data_balance_valid_x_m1[\"week_number2\"] = data_balance_valid_x_m1[\"week_number\"]**2\n",
    "data_balance_valid_x_m1 = pd.get_dummies(data_balance_valid_x_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    data_balance_valid_x_m1[\"month_\"+str(1+i)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac04fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    if i == 1:\n",
    "        pass\n",
    "    data_balance_valid_x_m1[\"weekofmonth_\"+str(1+i)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba1727",
   "metadata": {},
   "outputs": [],
   "source": [
    "poission_model_m2 = sm.GLM(data_balance_train_y.astype(int), data_balance_train_x_m1.astype(float), family=sm.families.Poisson())\n",
    "result_m2 = poission_model_m2.fit()\n",
    "result_m2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balance_estimate_m2 = result_m2.predict(data_balance_valid_x_m1.astype(float))\n",
    "MSPE(data_balance_estimate_m2, data_balance_valid_y)\n",
    "MAPE(data_balance_estimate_m2, data_balance_valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5353f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although using a balanced model has better fit on the training set, the MSPE and MAPE are still larger then the first model.\n",
    "# So for this submission, I sitll use the m1 for prediction.\n",
    "data_lastWeek = data[data[\"week_number\"] == train_week][[\"uu_id\", \"average_wage\"]]\n",
    "data_lastWeek = data_lastWeek.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59287a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = data_pred_query.copy()\n",
    "data_pred = data_pred.set_index('uu_id').join(data_lastWeek.set_index('uu_id'))\n",
    "data_pred.head()\n",
    "data_pred = dataIdentifyDWM(data_pred)\n",
    "data_pred = dataFillNa(data_pred, 0)\n",
    "data_pred[\"month\"] = data_pred[\"month\"].astype(str)\n",
    "data_pred = data_pred.drop(\"date\",1)\n",
    "data_pred = pd.get_dummies(data_pred)\n",
    "for i in range(8):\n",
    "    data_pred[\"month_\"+str(1+i)] = 0\n",
    "for i in range(5):\n",
    "    if i == 1:\n",
    "        pass\n",
    "    data_pred[\"weekofmonth_\"+str(1+i)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f1df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = result.predict(data_pred.astype(float))\n",
    "output_df = pd.DataFrame(output, columns=[\"total_claims\"])[\"total_claims\"]\n",
    "output_df[\"uu_id\"] = output_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f7e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred_query = data_pred_query.merge(output_df, on = \"uu_id\")\n",
    "data_pred_query = data_pred_query[[\"uu_id\", \"total_claims\", \"week_number\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f65631",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## This can also be a good place for you to cleanup any input/output and export your results to a file.\n",
    "data_pred_query.to_csv(\"submission_prediction_output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
