{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c12d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"%logstop\\n%logstart -t -r -q ipython_command_log.py global\\n\\n#- IRONHACKS RESEARCH TRACKING CODE\\n#----------------------------------\\n# The following code is used to help our research team understand how you \\n# our notebook environment. We do not collect any personal information with\\n# the following code, it is used to measure when and how often you work on\\n# your submission files.\\n\\nimport os\\nfrom datetime import datetime\\nimport IPython.core.history as history\\n\\nha = history.HistoryAccessor()\\nha_tail = ha.get_tail(1)\\nha_cmd = next(ha_tail)\\nsession_id = str(ha_cmd[0])\\ncommand_id = str(ha_cmd[1])\\ntimestamp = datetime.utcnow().isoformat()\\nhistory_line = ','.join([session_id, command_id, timestamp]) + '\\\\n'\\nlogfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\\nlogfile.write(history_line)\\nlogfile.close()\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ea975",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system('pip install db-dtypes')\n",
    "get_ipython().system('pip install xgboost')\n",
    "get_ipython().system('pip install impyute')\n",
    "get_ipython().system('pip install prophet')\n",
    "get_ipython().system('pip install plotly')\n",
    "get_ipython().system('pip install plotly-geo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f91d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import sklearn.experimental.enable_iterative_imputer\n",
    "import sklearn.impute\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13761431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb6f2e7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b109aa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "def query(table):\n",
    "    bigquery_client = bigquery.Client(project='ironhacks-data')\n",
    "    query_str = f'''\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.{table}`\n",
    "'''\n",
    "    query_job = bigquery_client.query(query_str)\n",
    "    data = query_job.to_dataframe()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d99ba",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def combine(u, w):\n",
    "    '''\n",
    "    Joins the unemployment data and the wage data on `uu_id`\n",
    "    '''\n",
    "    ww = w.loc[:, ['uu_id', 'average_wage']]\n",
    "    d = u.join(ww.set_index('uu_id'), on='uu_id')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f888f33",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_raw(csv_name='0_raw.csv'):\n",
    "    '''\n",
    "    Loads the unemployment and wage data and does some basic cleaning\n",
    "    '''\n",
    "    if not os.path.isfile(csv_name):\n",
    "        u = query('unemployment_data')\n",
    "        w = query('wage_data')\n",
    "        raw = combine(u, w)\n",
    "        raw.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        raw = pd.read_csv(csv_name)\n",
    "    raw = raw.drop(['tract', 'timeperiod'], axis=1)\n",
    "    raw = raw.sort_values(by=['uu_id', 'week_number'])\n",
    "    raw = raw.drop_duplicates()\n",
    "    raw = raw.replace({np.nan: None})\n",
    "    raw = raw.reset_index(0, drop=True)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022de73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_raw().to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db3b2f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# define relevant columns based on categories \n",
    "COL_MAP = {\n",
    "    'edu': ['edu_8th_or_less', 'edu_grades_9_11', 'edu_hs_grad_equiv', 'edu_post_hs', 'edu_unknown'],\n",
    "    'race': ['race_amerindian', 'race_asian', 'race_black', 'race_noanswer', 'race_hawaiiannative', 'race_other', 'race_white'],    \n",
    "    'gender': ['gender_female', 'gender_male', 'gender_na'],\n",
    "    'industry': ['top_category_employer1', 'top_category_employer2', 'top_category_employer3']        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec857bd6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_cols(names):\n",
    "    l = []\n",
    "    for name in names:\n",
    "        if name in COL_MAP:\n",
    "            l += COL_MAP[name]\n",
    "        else:\n",
    "            l += [name]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637dff23",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def subset(df, uu_id):        \n",
    "    return df.loc[df.uu_id == df.uu_id.unique()[uu_id], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc9304",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def convert_to_submission(results_csv, week_number_to_submit=40):\n",
    "    r = pd.read_csv(results_csv)\n",
    "    last = r.loc[r.week_number == week_number_to_submit, ['uu_id', 'predicted']]\n",
    "    last.index = last.uu_id\n",
    "    uuid_map = last.to_dict(orient='dict')['predicted']\n",
    "    p = query('prediction_list')\n",
    "    p['total_claims'] = p['uu_id'].map(uuid_map)\n",
    "    p.to_csv('submission_prediction_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39d0fca",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_week_number_map(g, colname):\n",
    "    '''\n",
    "    Creates a dictionary that maps from week number to an existing value in a given `colname`\n",
    "    '''\n",
    "    g = g[['week_number', colname]]\n",
    "    week_number_map = dict(sorted(g.values.tolist()))\n",
    "    return week_number_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc7e34",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_county(tract_name):\n",
    "    m = re.search('Census Tract \\S+, (.+) County, Indiana', tract_name)\n",
    "    county = m.group(1)\n",
    "    return county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c148f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def week_number_to_date(week_number, first_week_date='20220101'):\n",
    "    '''\n",
    "    Prepare a date column for ARIMA\n",
    "    '''\n",
    "    return pd.to_datetime(first_week_date, format='%Y%m%d') + pd.DateOffset(days=7*(week_number - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a42d9d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def insert_na_week_number(g, max_week_number=37):    \n",
    "    d = {}\n",
    "    for colname in g.columns:\n",
    "        if colname == 'week_number':\n",
    "            continue\n",
    "        week_number_map = get_week_number_map(g, colname)\n",
    "        series = pd.Series(range(1, max_week_number+1))        \n",
    "        d[colname] = series.map(week_number_map)        \n",
    "        \n",
    "    df = pd.DataFrame(d)\n",
    "    df['week_number'] = range(1, max_week_number+1)\n",
    "    df['uu_id'] = [v for v in df['uu_id'].unique() if type(v) == str][0]\n",
    "    df['average_wage'] = [v for v in g['average_wage'].unique()][0]\n",
    "    df['countyfips'] = [v for v in g['countyfips'].unique()][0]\n",
    "    df['county'] = get_county([v for v in g['tract_name'].unique()][0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1db7a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_raw_full(csv_name='1_raw_full.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        raw = load_raw()\n",
    "        raw_full = raw.groupby('uu_id').apply(insert_na_week_number).reset_index(0, drop=True)\n",
    "        raw_full['date'] = raw_full['week_number'].apply(week_number_to_date)\n",
    "        raw_full = raw_full.drop(['tract_name'], axis=1)\n",
    "        raw_full.to_csv(csv_name, index=False)        \n",
    "    else:\n",
    "        raw_full = pd.read_csv(csv_name)\n",
    "    return raw_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e72561",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "load_raw_full().to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc6623",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_impute(n=6):\n",
    "    raw = load_raw_full()\n",
    "    imp = load_imp_tot()\n",
    "    fig, axs = plt.subplots(ncols=n, sharey=False, figsize=(n*3, 3))\n",
    "    for i in range(n):\n",
    "        rraw = subset(raw, i)\n",
    "        iimp = subset(imp, i)\n",
    "        ax = axs[i]\n",
    "        ax.plot(rraw.week_number, rraw.total_claims, 'o', label='original')\n",
    "        ax.plot(iimp.week_number, iimp.total_claims, '-', label='imputed')\n",
    "        ax.set_xlim(0, 42)\n",
    "    axs[-1].legend(fancybox=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5eba45",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def imp_tot(g):\n",
    "    g['total_claims'] = g['total_claims'].interpolate(method='linear')\n",
    "    g = g[g['total_claims'].notna()]\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66de79",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_imp_tot(csv_name='2_imp_tot.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        d = load_raw_full()\n",
    "        d = d.groupby(['uu_id']).apply(imp_tot).reset_index(0, drop=True)\n",
    "        d.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        d = pd.read_csv(csv_name)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce9596f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_impute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4fae53",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def replace_na_cols(g):\n",
    "    '''\n",
    "    If a column only has None or zero values, replace that entire columnn with zeros\n",
    "    '''\n",
    "    x = g.copy()\n",
    "    for col in g.columns:\n",
    "        cond1 = g[col].isnull()\n",
    "        cond2 = g[col] == 0\n",
    "        if (cond1 | cond2).all():\n",
    "            x[col] = 0        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bd8b88",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_iterative(df):\n",
    "    '''\n",
    "    Wrapper fucntion for IterativeImputer for a generic data frame. \n",
    "    Mostly, for testing. We might need need this function\n",
    "    Impute data assuming there are zero columns where all the values are NA\n",
    "    '''\n",
    "    imputer = sklearn.impute.IterativeImputer(random_state=0, min_value=0)\n",
    "    imputed_cols = imputer.fit_transform(df)\n",
    "    df_imputed = pd.DataFrame(imputed_cols, columns=df.columns)\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd7b614",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def iter_cat(g):\n",
    "    g = replace_na_cols(g)    \n",
    "    for cat in ['edu', 'race', 'gender']:\n",
    "        gg = g.loc[:, COL_MAP[cat] + ['total_claims']]\n",
    "        yield cat, gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b680c1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def print_impute_cat(test_subset, impute_func):\n",
    "    for cat, gg in iter_cat(test_subset):\n",
    "        line = '*'*len(cat)\n",
    "        print(line)\n",
    "        print(cat)\n",
    "        print(line)\n",
    "        print(impute_func(gg).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6afdcf2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print_impute_cat(subset(load_imp_tot(), 6), impute_iterative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5db720",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_rowsum(df, target_col='total_claims'):\n",
    "    l = []\n",
    "    for idx, row in df.iterrows():\n",
    "        n_unknowns = row.isna().sum()        \n",
    "        if n_unknowns == 1:\n",
    "            others = row[~row.isna() & (row.index != target_col)]\n",
    "            val = row[target_col] - others.sum()\n",
    "            val = val if val > 0 else 0\n",
    "            row[row.isna()] = val\n",
    "        l.append(row)\n",
    "    df = pd.DataFrame(l).reset_index(0, drop=True)\n",
    "    \n",
    "    l = []\n",
    "    for idx, row in df.iterrows():\n",
    "        n_unknowns = row.isna().sum()        \n",
    "        \n",
    "        weights = {}\n",
    "        for col in row[row.isna()].index:\n",
    "            weights[col] = df[col].mean()\n",
    "        weights = {k:v/sum(weights.values()) for k, v in weights.items()}       \n",
    "        \n",
    "        if n_unknowns > 1:            \n",
    "            others = row[~row.isna() & (row.index != target_col)]\n",
    "            row[row.isna()] = row[row.isna()].index.map(weights)*(row[target_col] - others.sum())            \n",
    "        l.append(row)\n",
    "        \n",
    "    df_imputed = pd.DataFrame(l).reset_index(0, drop=True)\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb91045",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print_impute_cat(subset(load_imp_tot(), 6), impute_rowsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542484f0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_all(df):\n",
    "    x = df.copy().reset_index(0, drop=True)\n",
    "    for cat, gg in iter_cat(df):\n",
    "        df_imputed = impute_rowsum(gg)\n",
    "        df_imputed = df_imputed.drop('total_claims', axis=1)\n",
    "        x[COL_MAP[cat]] = df_imputed\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a467875",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_clean(csv_name='3_clean.csv'):    \n",
    "    if not os.path.isfile(csv_name):\n",
    "        imp_tot = load_imp_tot()\n",
    "        imp = imp_tot.groupby('uu_id').apply(impute_all).reset_index(0, drop=True)\n",
    "        imp['date'] = imp['week_number'].apply(week_number_to_date)\n",
    "        imp.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        imp = pd.read_csv(csv_name)\n",
    "    \n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ffdb6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "load_clean().to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4feacc3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_logistic(g, ycol):\n",
    "    g = g[[ycol, 'week_number', 'total_claims']]\n",
    "    xcols = ['week_number', 'total_claims']\n",
    "    ycols = [ycol]\n",
    "    \n",
    "    mask_train = ~g[ycol].isnull()\n",
    "    x_train, x_test = g.loc[mask_train, xcols], g.loc[~mask_train, xcols]\n",
    "    y_train, y_test = g.loc[mask_train, ycols], g.loc[~mask_train, ycols]\n",
    "    \n",
    "    if y_train.shape[0] == 0:\n",
    "        g[ycol] = None\n",
    "        return g[ycol]\n",
    "    \n",
    "    classes = y_train[ycol].unique()\n",
    "    if len(classes) == 1:\n",
    "        yhat = [classes[0]]\n",
    "    else:\n",
    "        model = sklearn.linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=10000).fit(x_train, y_train.values.ravel())\n",
    "        yhat = model.predict(x_test)\n",
    "    g.loc[~mask_train, ycols] = yhat\n",
    "    return g[ycol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a37e6e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_industry(g, max_week_number=37):\n",
    "    g = g.loc[g.week_number <= max_week_number, :]\n",
    "    x = g.copy()\n",
    "    for colname in COL_MAP['industry']:\n",
    "        x[colname] = impute_logistic(g, colname)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c5f61",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_imp_industry(csv_name='4_imp_industry.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        d = load_clean()\n",
    "        d = d.groupby('uu_id').apply(impute_industry).reset_index(0, drop=True)\n",
    "        d.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        d = pd.read_csv(csv_name)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7a087",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "load_imp_industry().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3285b88f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def feature_engineer(d):\n",
    "    d['gender_male_ratio'] = d['gender_male'] / d['total_claims']\n",
    "    d['edu_post_hs_ratio'] = d['edu_post_hs'] / d['total_claims']\n",
    "    d['race_white_ratio'] = d['race_white'] / d['total_claims']\n",
    "    d['race_black_ratio'] = d['race_black'] / d['total_claims']\n",
    "    d = d.drop(get_cols(['gender', 'edu', 'race']), axis=1)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26648413",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_featured(csv_name='5_featured.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        d = load_imp_industry()\n",
    "        d = feature_engineer(d)\n",
    "    else:\n",
    "        d = pd.read_csv(csv_name)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd9947",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "load_featured().to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c6e39c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_tot_by_county(d):\n",
    "    l = []\n",
    "    for (county, week_number), g in d.groupby(['county', 'week_number']):        \n",
    "        l.append({\n",
    "            'county': county,\n",
    "            'fips': g.countyfips.values[0],\n",
    "            'week_number': week_number,\n",
    "            'total_claims': g.total_claims.mean()\n",
    "        })\n",
    "    c = pd.DataFrame(l)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_tot_by_county(load_featured())\n",
    "c = c.loc[c.week_number == 20, :]\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = c.total_claims\n",
    "endpts = list(np.mgrid[min(values):max(values):4j])\n",
    "colorscale = [\"#030512\",\"#1d1d3b\",\"#323268\",\"#3d4b94\",\"#3e6ab0\",\n",
    "              \"#4989bc\",\"#60a7c7\",\"#85c5d3\",\"#b7e0e4\",\"#eafcfd\"]\n",
    "# fig = plotly.figure_factory.create_choropleth(\n",
    "#     fips=c.fips, values=values, scope=['Indiana'], show_state_data=True,\n",
    "#     colorscale=colorscale, binning_endpoints=endpts, round_legend_values=True,\n",
    "#     plot_bgcolor='rgb(229,229,229)',\n",
    "#     paper_bgcolor='rgb(229,229,229)',\n",
    "#     legend_title='Average Total Claims by County',\n",
    "#     county_outline={'color': 'rgb(255,255,255)', 'width': 0.5},\n",
    "#     exponent_format=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a582133",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = c.total_claims\n",
    "endpts = list(np.mgrid[min(values):max(values):4j])\n",
    "colorscale = [\"#030512\",\"#1d1d3b\",\"#323268\",\"#3d4b94\",\"#3e6ab0\",\n",
    "              \"#4989bc\",\"#60a7c7\",\"#85c5d3\",\"#b7e0e4\",\"#eafcfd\"]\n",
    "fig = plotly.figure_factory.create_choropleth(\n",
    "    fips=c.fips, values=values, scope=['Indiana'], show_state_data=True,\n",
    "    colorscale=colorscale, binning_endpoints=endpts, round_legend_values=True,\n",
    "    plot_bgcolor='rgb(229,229,229)',\n",
    "    paper_bgcolor='rgb(229,229,229)',\n",
    "    legend_title='Average Total Claims by County',\n",
    "    county_outline={'color': 'rgb(255,255,255)', 'width': 0.5},\n",
    "    exponent_format=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca973444",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "get_ipython().system('pip install db-dtypes')\n",
    "get_ipython().system('pip install xgboost')\n",
    "get_ipython().system('pip install impyute')\n",
    "get_ipython().system('pip install prophet')\n",
    "get_ipython().system('pip install plotly')\n",
    "get_ipython().system('pip install plotly-geo')\n",
    "get_ipython().system('pip install geopandas')\n",
    "get_ipython().system('pip install pyshp')\n",
    "get_ipython().system('pip install shapely')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
