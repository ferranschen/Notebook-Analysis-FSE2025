{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"%logstop\\n%logstart -t -r -q ipython_command_log.py global\\n\\n#- IRONHACKS RESEARCH TRACKING CODE\\n#----------------------------------\\n# The following code is used to help our research team understand how you \\n# our notebook environment. We do not collect any personal information with\\n# the following code, it is used to measure when and how often you work on\\n# your submission files.\\n\\nimport os\\nfrom datetime import datetime\\nimport IPython.core.history as history\\n\\nha = history.HistoryAccessor()\\nha_tail = ha.get_tail(1)\\nha_cmd = next(ha_tail)\\nsession_id = str(ha_cmd[0])\\ncommand_id = str(ha_cmd[1])\\ntimestamp = datetime.utcnow().isoformat()\\nhistory_line = ','.join([session_id, command_id, timestamp]) + '\\\\n'\\nlogfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\\nlogfile.write(history_line)\\nlogfile.close()\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ceeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"\\n#- INSTALL ADDITIONAL LIBRARIES IF REQUIRED\\n#------------------------------------------\\n# This is normally not required. The hub environment comes preinstaled with \\n# many packages that you can already use without setup. In case there is some\\n# other library you would like to use that isn't on the list you run this command\\n# once to install them.  If it is already installed this command has no effect.\\n\\n#!python3 -m pip install pandas\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd182c6e",
   "metadata": {},
   "source": [
    "- IMPORT THE LIBRARIES YOU WILL USE\n",
    "------------------------------------------\n",
    "You only need to import packages one time per notebook session. To keep your\n",
    "notebook clean and organized you can handle all imports at the top of your file.\n",
    "The following are included for example purposed, feel free to modify or delete \n",
    "anything in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129730b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551f4b5",
   "metadata": {},
   "source": [
    "- DEFINE YOUR CLASSES AND FUNCTIONS \n",
    "-----------------------------------\n",
    "This is not required, but is helpful in keeping your notebook organized. \n",
    "You can use the following cell or several cells to define your functions\n",
    "and classes to keep them separate from your analysis or results code.\n",
    "In general it useful to define your methods in a separate cell from where\n",
    "it is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c18a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGQUERY_PROJECT = 'ironhacks-data'\n",
    "bigquery_client = bigquery.Client(project=BIGQUERY_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install db-dtypes\n",
    "query_unemployment = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.unemployment_data` \n",
    "\"\"\"\n",
    "query = bigquery_client.query(query_unemployment)\n",
    "df_unemployment = query.to_dataframe()\n",
    "#df_unemployment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c3d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_wage = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.wage_data`\n",
    "\"\"\"\n",
    "query = bigquery_client.query(query_wage)\n",
    "df_wage = query.to_dataframe()\n",
    "#df_wage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5433f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_pred_list = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.prediction_list`\n",
    "\"\"\"\n",
    "query = bigquery_client.query(query_pred_list)\n",
    "df_pred_list = query.to_dataframe()\n",
    "#df_pred_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ecdb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_schema = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.INFORMATION_SCHEMA.TABLES`\n",
    "\"\"\"\n",
    "query = bigquery_client.query(query_schema)\n",
    "df_schema = query.to_dataframe()\n",
    "#df_schema.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f0e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_three_col = df_unemployment[[\"uu_id\", \"week_number\", \"total_claims\"]]\n",
    "#df_three_col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_three_col = df_three_col.drop_duplicates()\n",
    "#print(df_three_col.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb03186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_three_col.sort_values(by=['uu_id', \"week_number\"],inplace=True)\n",
    "#df_three_col.head(21)\n",
    "#df_three_col.tail(3)\n",
    "#uu_id\tweek_number\ttotal_claims\n",
    "#1876\t001cd9ae23064d7f0fd3cd327c873d8d\t31\t34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df_three_col['week_number']\n",
    "tmp_df = tmp_df.drop_duplicates()\n",
    "print(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e69dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns = ['uu_id', 'total_claims', 'week_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e0e3a7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for cur_uu_id in df_pred_list['uu_id']:\n",
    "    #print(uu_id)\n",
    "    test_data = df_three_col[df_three_col[\"uu_id\"].isin([cur_uu_id]) ]\n",
    "    #test_data = test_data.tail(3)\n",
    "    week_list = test_data['week_number'].tolist()\n",
    "    y_pred = -1\n",
    "    count = 0\n",
    "    sum = 0\n",
    "    for week_id in range(33,38):\n",
    "        if week_id in week_list:\n",
    "            count+=1\n",
    "            tmp_row = test_data[test_data['week_number'] == week_id  ]\n",
    "            sum+= int( tmp_row['total_claims'])\n",
    "    if count > 0:\n",
    "        y_pred = int(sum/count)\n",
    "    else:\n",
    "        max_week = max(week_list)\n",
    "        tmp_row = test_data[test_data['week_number'] ==  max_week  ] \n",
    "        y_pre = tmp_row['total_claims']\n",
    "    cur_row =  pd.DataFrame([[cur_uu_id, y_pred, 42]], columns=['uu_id', 'total_claims', 'week_number'] )\n",
    "    res = pd.concat([res,cur_row] ,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b417d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "res.to_csv(\"Nov28_submission_prediction_output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
