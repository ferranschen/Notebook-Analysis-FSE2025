{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d322b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"%logstop\\n%logstart -t -r -q ipython_command_log.py global\\n\\n#- IRONHACKS RESEARCH TRACKING CODE\\n#----------------------------------\\n# The following code is used to help our research team understand how you \\n# our notebook environment. We do not collect any personal information with\\n# the following code, it is used to measure when and how often you work on\\n# your submission files.\\n\\nimport os\\nfrom datetime import datetime\\nimport IPython.core.history as history\\n\\nha = history.HistoryAccessor()\\nha_tail = ha.get_tail(1)\\nha_cmd = next(ha_tail)\\nsession_id = str(ha_cmd[0])\\ncommand_id = str(ha_cmd[1])\\ntimestamp = datetime.utcnow().isoformat()\\nhistory_line = ','.join([session_id, command_id, timestamp]) + '\\\\n'\\nlogfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\\nlogfile.write(history_line)\\nlogfile.close()\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21159a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system('pip install db-dtypes')\n",
    "get_ipython().system('pip install xgboost')\n",
    "get_ipython().system('pip install impyute')\n",
    "get_ipython().system('pip install prophet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07327d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import sklearn.experimental.enable_iterative_imputer\n",
    "import sklearn.impute\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74811414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e4ac90",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a5be2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "def query(table):\n",
    "    bigquery_client = bigquery.Client(project='ironhacks-data')\n",
    "    query_str = f'''\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.{table}`\n",
    "'''\n",
    "    query_job = bigquery_client.query(query_str)\n",
    "    data = query_job.to_dataframe()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6402f7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def combine(u, w):\n",
    "    '''\n",
    "    Joins the unemployment data and the wage data on `uu_id`\n",
    "    '''\n",
    "    ww = w.loc[:, ['uu_id', 'average_wage']]\n",
    "    d = u.join(ww.set_index('uu_id'), on='uu_id')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93584e55",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_raw(csv_name='0_raw.csv'):\n",
    "    '''\n",
    "    Loads the unemployment and wage data and does some basic cleaning\n",
    "    '''\n",
    "    if not os.path.isfile(csv_name):\n",
    "        u = query('unemployment_data')\n",
    "        w = query('wage_data')\n",
    "        raw = combine(u, w)\n",
    "        raw.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        raw = pd.read_csv(csv_name)\n",
    "    raw = raw.drop(['countyfips', 'tract', 'tract_name', 'timeperiod'], axis=1)\n",
    "    raw = raw.sort_values(by=['uu_id', 'week_number'])\n",
    "    raw = raw.drop_duplicates()\n",
    "    raw = raw.replace({np.nan: None})\n",
    "    raw = raw.reset_index(0, drop=True)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57dfc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5755b4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# define relevant columns based on categories \n",
    "COL_MAP = {\n",
    "    'edu': ['edu_8th_or_less', 'edu_grades_9_11', 'edu_hs_grad_equiv', 'edu_post_hs', 'edu_unknown'],\n",
    "    'race': ['race_amerindian', 'race_asian', 'race_black', 'race_noanswer', 'race_hawaiiannative', 'race_other', 'race_white'],    \n",
    "    'gender': ['gender_female', 'gender_male', 'gender_na'],\n",
    "    'industry': ['top_category_employer1', 'top_category_employer2', 'top_category_employer3']        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d150e4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_cols(names):\n",
    "    l = []\n",
    "    for name in names:\n",
    "        if name in COL_MAP:\n",
    "            l += COL_MAP[name]\n",
    "        else:\n",
    "            l += [name]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f955992",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def week_number_to_date(week_number, first_week_date='20220101'):\n",
    "    '''\n",
    "    Prepare a date column for ARIMA\n",
    "    '''\n",
    "    return pd.to_datetime(first_week_date, format='%Y%m%d') + pd.DateOffset(days=7*(week_number - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92422fe5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_subset(df, uu_id):        \n",
    "    return df.loc[df.uu_id == df.uu_id.unique()[uu_id], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91f033",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def convert_to_submission(results_csv, observed_label='total_claims', week_number_to_submit=40):\n",
    "    r = pd.read_csv(results_csv)\n",
    "    # last_few = r.loc[(30 <= r.week_number) & (r.week_number <= 37), :]\n",
    "    # print('rms:', get_rms(last_few[observed_label], last_few.predicted))\n",
    "    # print('mae:', get_mae(last_few[observed_label], last_few.predicted))\n",
    "    last = r.loc[r.week_number == week_number_to_submit, ['uu_id', 'predicted']]\n",
    "    last.index = last.uu_id\n",
    "    uuid_map = last.to_dict(orient='dict')['predicted']\n",
    "    p = query('prediction_list')\n",
    "    p['total_claims'] = p['uu_id'].map(uuid_map)    \n",
    "    p.to_csv('submission_prediction_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b890d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_week_number_map(g, colname):\n",
    "    '''\n",
    "    Creates a dictionary that maps from week number to an existing value in a given `colname`\n",
    "    '''\n",
    "    g = g[['week_number', colname]]\n",
    "    week_number_map = dict(sorted(g.values.tolist()))\n",
    "    return week_number_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a621681",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def insert_na_week_number(g, max_week_number=43):    \n",
    "    d = {}\n",
    "    for colname in g.columns:\n",
    "        if colname == 'week_number':\n",
    "            continue\n",
    "        week_number_map = get_week_number_map(g, colname)\n",
    "        series = pd.Series(range(1, max_week_number+1))        \n",
    "        d[colname] = series.map(week_number_map)        \n",
    "        \n",
    "    df = pd.DataFrame(d)\n",
    "    df['week_number'] = range(1, max_week_number+1)\n",
    "    df['uu_id'] = [v for v in df['uu_id'].unique() if type(v) == str][0]\n",
    "    df['average_wage'] = [v for v in g['average_wage'].unique()][0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a50062",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_raw_full(csv_name='1_raw_full.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        raw = load_raw()\n",
    "        raw_full = raw.groupby('uu_id').apply(insert_na_week_number).reset_index(0, drop=True)\n",
    "        raw_full['date'] = raw_full['week_number'].apply(week_number_to_date)\n",
    "        raw_full.to_csv(csv_name, index=False)\n",
    "        \n",
    "    else:\n",
    "        raw_full = pd.read_csv(csv_name)\n",
    "    return raw_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032aad8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "load_raw_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec908f8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_iterative(df):\n",
    "    '''\n",
    "    Wrapper fucntion for IterativeImputer for a generic data frame. \n",
    "    Mostly, for testing. We might need need this function\n",
    "    Impute data assuming there are zero columns where all the values are NA\n",
    "    '''\n",
    "    imputer = sklearn.impute.IterativeImputer(random_state=0, min_value=0)\n",
    "    imputed_cols = imputer.fit_transform(df)\n",
    "    df_imputed = pd.DataFrame(imputed_cols, columns=df.columns)\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f064923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_impute_iterative():\n",
    "    raw_full = load_raw_full()\n",
    "    nplots = 6\n",
    "    \n",
    "    fig, axs = plt.subplots(ncols=nplots, sharey=True, figsize=(15, 3))\n",
    "    for i, (uu_id, g) in enumerate(raw_full.groupby('uu_id')):\n",
    "        g_imp = impute_iterative(g.loc[:, ['week_number', 'total_claims']])    \n",
    "        if i < nplots:\n",
    "            ax = axs[i]\n",
    "            ax.plot(g.week_number, g.total_claims, 'o-', zorder=10, label='raw')\n",
    "            ax.plot(g_imp.week_number, g_imp.total_claims, 'o--', zorder=0, label='imputed')\n",
    "            ax.set_title(f'uu_id {i}')\n",
    "            ax.set_xlabel('week_number')\n",
    "        # elif uu_id == 'ffbc87dc4bde6828daff6ad43e12db4a':\n",
    "        #     ax = axs[-1]            \n",
    "        #     ax.plot(g.week_number, g.total_claims, 'o-', zorder=10, label='raw')\n",
    "        #     ax.plot(g_imp.week_number, g_imp.total_claims, 'o--', zorder=0, label='imputed')\n",
    "        #     ax.set_title(f'uu_id {i}')\n",
    "        #     ax.set_xlabel('week_number')\n",
    "\n",
    "        \n",
    "    axs[0].set_ylabel('total_claims')\n",
    "    axs[-1].legend(frameon=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10200d28",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_impute_iterative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e2f9c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_total_claims(g):\n",
    "    x = g.copy().reset_index(0, drop=True)\n",
    "    g_imp = impute_iterative(g.loc[:, ['week_number', 'total_claims']]).reset_index(0, drop=True)\n",
    "    x['total_claims'] = g_imp['total_claims']\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4eab7d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_imp_tot(csv_name='2_imp_tot.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        raw_full = load_raw_full()\n",
    "        imp_tot = raw_full.groupby(['uu_id']).apply(impute_total_claims).reset_index(0, drop=True)\n",
    "        imp_tot.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        imp_tot = pd.read_csv(csv_name)\n",
    "    return imp_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8477cdc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "imp_tot = load_imp_tot()\n",
    "imp_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71532c51",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def replace_na_cols(g):\n",
    "    '''\n",
    "    If a column only has None or zero values, replace that entire columnn with zeros\n",
    "    '''\n",
    "    x = g.copy()\n",
    "    for col in g.columns:\n",
    "        cond1 = g[col].isnull()\n",
    "        cond2 = g[col] == 0\n",
    "        if (cond1 | cond2).all():\n",
    "            x[col] = 0        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f81d33b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def iter_cat(g):\n",
    "    g = replace_na_cols(g)    \n",
    "    for cat in ['edu', 'race', 'gender']:\n",
    "        gg = g.loc[:, COL_MAP[cat] + ['total_claims']]\n",
    "        yield cat, gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d812d320",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def print_impute_cat(test_subset, impute_func):\n",
    "    for cat, gg in iter_cat(test_subset):\n",
    "        print(impute_func(gg).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93fa60",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print_impute_cat(get_subset(imp_tot, 6), impute_iterative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c69e9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_rowsum(df, target_col='total_claims'):\n",
    "    l = []\n",
    "    for idx, row in df.iterrows():\n",
    "        n_unknowns = row.isna().sum()        \n",
    "        if n_unknowns == 1:\n",
    "            others = row[~row.isna() & (row.index != target_col)]\n",
    "            val = row[target_col] - others.sum()\n",
    "            val = val if val > 0 else 0\n",
    "            row[row.isna()] = val\n",
    "        l.append(row)\n",
    "    df = pd.DataFrame(l).reset_index(0, drop=True)\n",
    "    \n",
    "    l = []\n",
    "    for idx, row in df.iterrows():\n",
    "        n_unknowns = row.isna().sum()        \n",
    "        \n",
    "        weights = {}\n",
    "        for col in row[row.isna()].index:\n",
    "            weights[col] = df[col].mean()\n",
    "        weights = {k:v/sum(weights.values()) for k, v in weights.items()}       \n",
    "        \n",
    "        if n_unknowns > 1:            \n",
    "            others = row[~row.isna() & (row.index != target_col)]\n",
    "            row[row.isna()] = row[row.isna()].index.map(weights)*(row[target_col] - others.sum())            \n",
    "        l.append(row)\n",
    "        \n",
    "    df_imputed = pd.DataFrame(l).reset_index(0, drop=True)\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d3955d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print_impute_cat(get_subset(imp_tot, 6), impute_rowsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7223b6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_all(df):\n",
    "    x = df.copy().reset_index(0, drop=True)\n",
    "    for cat, gg in iter_cat(df):\n",
    "        df_imputed = impute_rowsum(gg)\n",
    "        df_imputed = df_imputed.drop('total_claims', axis=1)\n",
    "        x[COL_MAP[cat]] = df_imputed\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace88d1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_clean(csv_name='3_clean.csv'):    \n",
    "    if not os.path.isfile(csv_name):\n",
    "        imp_tot = load_imp_tot()\n",
    "        imp = imp_tot.groupby('uu_id').apply(impute_all).reset_index(0, drop=True)\n",
    "        imp['date'] = imp['week_number'].apply(week_number_to_date)\n",
    "        imp.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        imp = pd.read_csv(csv_name)\n",
    "    \n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ad5cd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "load_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec058499",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_logistic(g, ycol):\n",
    "    g = g[[ycol, 'week_number', 'total_claims']]\n",
    "    xcols = ['week_number', 'total_claims']\n",
    "    ycols = [ycol]\n",
    "    \n",
    "    mask_train = ~g[ycol].isnull()\n",
    "    x_train, x_test = g.loc[mask_train, xcols], g.loc[~mask_train, xcols]\n",
    "    y_train, y_test = g.loc[mask_train, ycols], g.loc[~mask_train, ycols]\n",
    "    \n",
    "    if y_train.shape[0] == 0:\n",
    "        g[ycol] = None\n",
    "        return g[ycol]\n",
    "    \n",
    "    classes = y_train[ycol].unique()\n",
    "    if len(classes) == 1:\n",
    "        yhat = [classes[0]]\n",
    "    else:\n",
    "        model = sklearn.linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=10000).fit(x_train, y_train.values.ravel())\n",
    "        yhat = model.predict(x_test)\n",
    "    g.loc[~mask_train, ycols] = yhat\n",
    "    return g[ycol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42bad3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_industry(g, max_week_number=37):\n",
    "    g = g.loc[g.week_number <= max_week_number, :]\n",
    "    x = g.copy()\n",
    "    for colname in COL_MAP['industry']:\n",
    "        x[colname] = impute_logistic(g, colname)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e6fde",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_imp_industry(csv_name='4_imp_industry.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        d = load_clean()\n",
    "        d = d.groupby('uu_id').apply(impute_industry).reset_index(0, drop=True)\n",
    "        d.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        d = pd.read_csv(csv_name)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94300e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_imp_industry()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9a2f1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef5b96",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def arimax(y, order, seasonal_order):\n",
    "    model = sm.tsa.statespace.SARIMAX(y, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "    results = model.fit(maxiter=300, disp=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc0378",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_best_params(y, period=0):\n",
    "    r1 = r2 = r3 = range(2)\n",
    "    pdq = list(itertools.product(r1, r2, r3))    \n",
    "    if period:\n",
    "        seasonal_pdq = [(x[0], x[1], x[2], period) for x in list(itertools.product(r1, r2, r3))]\n",
    "    else:\n",
    "        seasonal_pdq = [(0, 0, 0, 0)]\n",
    "    aic_min = np.inf\n",
    "    for order in pdq:\n",
    "        for seasonal_order in seasonal_pdq:\n",
    "            results = arimax(y, order, seasonal_order)\n",
    "            if results.aic < aic_min:\n",
    "                aic_min = results.aic\n",
    "                best_params = [order, seasonal_order, results.aic]            \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808d283",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def predict(g, ylabel='total_claims', target_week_number=41):\n",
    "    g = g.loc[:, ['uu_id', 'week_number', 'date', ylabel]]\n",
    "    g = g.set_index('date')\n",
    "    g.index = pd.DatetimeIndex(g.index).to_period('W')\n",
    "    y = g[ylabel].astype(np.float64)\n",
    "    best_params = get_best_params(y)\n",
    "    best_results = arimax(y, best_params[0], best_params[1])    \n",
    "    pred = best_results.get_prediction(start=week_number_to_date(target_week_number - 10), end=week_number_to_date(target_week_number), dynamic=False)\n",
    "    \n",
    "    x = g.join(pred.predicted_mean, on=g.index, how='outer')\n",
    "    x['date'] = x.key_0\n",
    "    ci = pred.conf_int()\n",
    "    x['ci_lower'] = ci.iloc[:, 0]\n",
    "    x['ci_upper'] = ci.iloc[:, 1]\n",
    "    x['uu_id'] = g['uu_id'].values[0]\n",
    "    x['week_number'] = np.arange(1, target_week_number + 1)\n",
    "    x['predicted'] = x['predicted_mean']\n",
    "    x = x.reset_index(0, drop=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d1fea",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def predict_all(d, ylabel, csv_name):\n",
    "    l = []\n",
    "    for i, (uu_id, g) in enumerate(d.groupby('uu_id')):    \n",
    "        if i % 100 == 0:\n",
    "            print(f'processed {i} UUIDs')\n",
    "        predicted = predict(g, ylabel=ylabel)\n",
    "        l.append(predicted)\n",
    "    df = pd.concat(l, ignore_index=True)\n",
    "    df.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8df03a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('results_arima.csv'):\n",
    "    predict_all(d, 'total_claims', 'results_arima.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e23a8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# now try to see if cleaning \"noises\" with exponentially weighted moving average (EWM) will help improve the model before doing ARIMA\n",
    "# and also figure out which value of the `alpha` parameters to use\n",
    "def moving_average(g, alpha=0.2): \n",
    "    x = g.copy()\n",
    "    x['predicted_ewm'] = g['total_claims'].ewm(alpha=alpha).mean()    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbe30a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_ewm(d, n=6):\n",
    "    fig, axs = plt.subplots(ncols=n, figsize=(18, 3), sharey=True)\n",
    "    for i in range(n):\n",
    "        g = get_subset(d, i)        \n",
    "        ax = axs[i]\n",
    "        ax.plot(g.week_number, g.total_claims, 'o-', label='observed')\n",
    "        for alpha in [0.6]:\n",
    "            ax.plot(g.week_number, moving_average(g, alpha=alpha).predicted_ewm, '-o', label=f'predicted_ewm: alpha={alpha}')\n",
    "    axs[-1].legend(fancybox=False)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13618171",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "test_ewm(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e33ac",
   "metadata": {},
   "source": [
    "it seems like alpha = 0.6 is a reasonable parameter to use for smoothing the curve without losing too much information of the peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafb399",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_ewm(csv_name='5_ewm.csv', alpha=0.6):    \n",
    "    if os.path.isfile(csv_name):\n",
    "        ewm = pd.read_csv(csv_name)\n",
    "    else:\n",
    "        d = load_imp_industry() \n",
    "        ewm = d.groupby(['uu_id']).apply(moving_average, alpha=alpha)\n",
    "        ewm.to_csv(csv_name, index=False)\n",
    "        ewm['total_claims'] = ewm['predicted_ewm']\n",
    "    return ewm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc22361",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_ewm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af033d64",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('results_arima_ewm.csv'):\n",
    "    predict_all(load_ewm(), 'predicted_ewm', 'results_arima_ewm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507183d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot(ax, g):    \n",
    "    for i, method in enumerate(g.method.unique()):        \n",
    "        gg = g.loc[g.method == method, :]\n",
    "        if i == 0:\n",
    "            ax.plot(gg.week_number, gg.total_claims, 'o-', label='observed')\n",
    "        ax.plot(gg.week_number, gg.predicted, 'o-', label=method)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc445af",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compare_ewm():\n",
    "    arma = pd.read_csv('results_arima.csv')\n",
    "    arma['method'] = 'arima'\n",
    "    arma_ewm = pd.read_csv('results_arima_ewm.csv')\n",
    "    arma_ewm['method'] = 'arima_ewm'\n",
    "    a = pd.concat([arma, arma_ewm], ignore_index=True)\n",
    "    fig, axs = plt.subplots(ncols=6, figsize=(18, 3), sharey=True)\n",
    "    for i, (uu_id, g) in enumerate(a.groupby('uu_id')):\n",
    "        if i < 6:\n",
    "            ax = axs[i]\n",
    "            plot(ax, g)\n",
    "            ax.set_xlabel('week_number')\n",
    "            ax.set_title(f'uu_id: {i}')\n",
    "    axs[0].set_ylabel('total_claims')\n",
    "    axs[-1].legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e364f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "compare_ewm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3fd110",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# check how good our prediction is\n",
    "def get_rms(y_observed, y_predicted):\n",
    "    n = len(y_observed)\n",
    "    rms = sum((y_observed - y_predicted)**2)/n\n",
    "    return rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f16e0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_mae(y_observed, y_predicted):\n",
    "    n = len(y_observed)\n",
    "    mae = sum(np.abs(y_observed - y_predicted))/n\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f3822",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compare_arima():\n",
    "    r = pd.read_csv('results_arima.csv')\n",
    "    rr = r.loc[(30 <= r.week_number) & (r.week_number <= 37), :]\n",
    "    y = rr.total_claims\n",
    "    yhat = rr.predicted\n",
    "    print('ARIMA without EWM smoothing')\n",
    "    print('rms:', get_rms(y, yhat))\n",
    "    print('mae:', get_mae(y, yhat))\n",
    "\n",
    "    rewm = pd.read_csv('results_arima_ewm.csv')\n",
    "    rrewm = rewm.loc[(30 <= rewm.week_number) & (rewm.week_number <= 37), :]\n",
    "    yhatewm = rrewm.predicted\n",
    "    print('ARIMA with EWM smoothing')\n",
    "    print('rms:', get_rms(y, yhatewm))\n",
    "    print('mae:', get_mae(y, yhatewm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5396d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_arima()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986b6d7e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Since ARIMA without smoothing seems better, we submit the corresponding results\n",
    "convert_to_submission('results_arima.csv', observed_label='total_claims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e4078",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_avg_total_claims(g):\n",
    "    return pd.DataFrame([{'uu_id': g.uu_id.values[0], 'average_wage': g.average_wage.values[0], 'avg_total_claims': g.total_claims.mean()}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788681a1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_avg_total_claims(d):\n",
    "    fig, axs = plt.subplots(ncols=6, figsize=(18, 3), sharey=True)\n",
    "    for i, week_number in enumerate([1, 6, 11, 16, 31, 36]):        \n",
    "            ax = axs[i]\n",
    "            dd = d.loc[d.week_number == week_number, ['average_wage', 'total_claims']]\n",
    "            ax.plot(dd.average_wage, dd.total_claims, 'o')\n",
    "            ax.set_title(f'week_number: {week_number}')\n",
    "            ax.set_xlabel('average_wage')\n",
    "    axs[0].set_ylabel('total_claims')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    avg = d.groupby('uu_id').apply(get_avg_total_claims).reset_index(0, drop=True)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(avg.average_wage, avg.avg_total_claims, 'o')    \n",
    "    ax.set_xlabel('average_wage')\n",
    "    ax.set_ylabel('average_total_claims')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print(avg[['average_wage', 'avg_total_claims']].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cee76e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_avg_total_claims(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5964cd7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_cat(d, cat):\n",
    "    colnames = COL_MAP[cat]\n",
    "    fig, axs = plt.subplots(ncols=6, figsize=(18, 3), sharey=True)\n",
    "    for i in range(6):\n",
    "        ax = axs[i]\n",
    "        dd = get_subset(d, i)[['week_number'] + colnames]\n",
    "        for colname in colnames:\n",
    "            ax.plot(dd.week_number, dd[colname], 'o-', label=colname)\n",
    "            ax.set_xlabel('week_number')\n",
    "            \n",
    "    axs[-1].legend(frameon=False)\n",
    "    axs[0].set_ylabel('claims')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04059b8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_cat(d, 'gender')\n",
    "plot_cat(d, 'edu')\n",
    "plot_cat(d, 'race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627868be",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_train_test(g, max_week_number=37):\n",
    "    xcols = COL_MAP['edu'] + COL_MAP['gender'] + COL_MAP['race'] + ['week_number']\n",
    "    ycols = ['total_claims']    \n",
    "    mask_train = g.week_number <= max_week_number\n",
    "    mask_test = g.week_number > max_week_number\n",
    "    \n",
    "    x_train, x_test = g.loc[mask_train, xcols], g.loc[mask_test, xcols]\n",
    "    y_train, y_test = g.loc[mask_train, ycols], g.loc[mask_test, ycols]\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df9beb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_rf(g, max_week_number=37):\n",
    "    x_train, x_test, y_train, y_test = get_train_test(g, max_week_number=max_week_number)\n",
    "    rf = sklearn.ensemble.RandomForestRegressor(n_estimators=100, random_state=0).fit(x_train, y_train.values.ravel())\n",
    "    yhat = rf.predict(pd.concat([x_train, x_test]))\n",
    "    return x_train, x_test, y_train, y_test, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566d9959",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_rf(d):\n",
    "    fig, axs = plt.subplots(ncols=6, figsize=(18, 3), sharey=True)\n",
    "    for i in range(6):\n",
    "        ax = axs[i]\n",
    "        dd = get_subset(d, i)\n",
    "        \n",
    "        x_train, x_test, y_train, y_test, yhat = run_rf(dd)\n",
    "        ax.plot(x_train.week_number, y_train, 'o-', label='original')\n",
    "        ax.plot(dd.week_number, yhat, 'o-', label='predict')\n",
    "        ax.set_xlabel('week_number')\n",
    "        ax.set_title(f'uu_id: {i}')\n",
    "            \n",
    "    axs[-1].legend(frameon=False)\n",
    "    axs[0].set_ylabel('claims')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f89ad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_rf(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac351215",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def rf_industry(g):\n",
    "    uu_id = g.uu_id.values[0]\n",
    "    gg = g[COL_MAP['industry'] + ['week_number', 'total_claims']]    \n",
    "    gg = gg.dropna()\n",
    "    gg = pd.get_dummies(gg)\n",
    "        \n",
    "    if gg.shape[0] == 0:\n",
    "        print(g.uu_id.values[0])\n",
    "        mean = g.total_claims.mean()\n",
    "        return pd.DataFrame([{'uu_id': uu_id, 'week_number': 38, 'total_claims': mean, 'predicted': mean}])\n",
    "    x = gg.drop(['total_claims'], axis=1)    \n",
    "    y = gg['total_claims']    \n",
    "    max_avail_week_number = int(x.week_number.max())\n",
    "    rf = sklearn.ensemble.RandomForestRegressor(n_estimators=100, random_state=0).fit(x, y.values.ravel())\n",
    "    last = x.loc[x.week_number == max_avail_week_number, :].copy()\n",
    "    last['week_number'] = max_avail_week_number + 1\n",
    "    x_test = pd.concat([x, last], ignore_index=True)\n",
    "    x_test['predicted'] = rf.predict(x_test)\n",
    "    result = x_test.copy()\n",
    "    result['total_claims'] = y.reset_index(0, drop=True)\n",
    "    result['uu_id'] = uu_id\n",
    "    return result[['uu_id', 'week_number', 'total_claims', 'predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d328b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_industry(d):\n",
    "    fig, axs = plt.subplots(ncols=6, figsize=(18, 3), sharey=True)\n",
    "    for i in range(6):\n",
    "        ax = axs[i]\n",
    "        dd = get_subset(d, i)\n",
    "        result = rf_industry(dd)\n",
    "        ax.plot(result.week_number, result.total_claims, 'o-', label='original')\n",
    "        ax.plot(result.week_number, result.predicted, 'o-', label='predict')\n",
    "        ax.set_xlabel('week_number')\n",
    "        ax.set_title(f'uu_id: {i}')\n",
    "            \n",
    "    axs[-1].legend(frameon=False)\n",
    "    axs[0].set_ylabel('claims')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95aa595",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_industry(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52701fae",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_rf_all(d, csv_name='results_rf.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        result_rf = d.groupby('uu_id').apply(rf_industry).reset_index(0, drop=True)\n",
    "        result_rf.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff381b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_rf_all(d)\n",
    "convert_to_submission('results_rf.csv', observed_label='total_claims', week_number_to_submit=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e083e734",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe9992",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_industry(g, cat=True):\n",
    "    gg = g[['uu_id', 'date', 'total_claims'] + COL_MAP['industry']]\n",
    "    if cat:\n",
    "        g_industry_cat = pd.get_dummies(gg[COL_MAP['industry']])\n",
    "        g_no_industry = gg.loc[:, gg.columns.difference(COL_MAP['industry'])]\n",
    "        gg = pd.concat([g_no_industry, g_industry_cat], axis=1)    \n",
    "    return gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a26c3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_var(g):    \n",
    "    g = g[['uu_id', 'date', 'total_claims'] + COL_MAP['edu'] + COL_MAP['race'] + COL_MAP['gender']]\n",
    "    uu_id = g.uu_id.values[0]\n",
    "    g.index = pd.DatetimeIndex(g.date)\n",
    "    g.index = pd.DatetimeIndex(g.index.values, freq=g.index.inferred_freq)\n",
    "    g = g.drop(['uu_id', 'date'], axis=1)\n",
    "    g = g.loc[:, (g != 0).any(axis=0)]\n",
    "    if g.shape[1] == 1:\n",
    "        total_claims = g.iloc[:, 0].values.mean()\n",
    "    else:\n",
    "        var = VAR(g)\n",
    "        results = var.fit(maxlags=3)\n",
    "        ahead = 5\n",
    "        total_claims = results.forecast(g.values[-10:], ahead)[:, 0]\n",
    "    print(g['total_claims'][-6:])\n",
    "    print(total_claims)\n",
    "    fig, ax = plt.subplots()\n",
    "    n = len(g.total_claims)\n",
    "    ax.plot(range(n), g.total_claims, 'o-', color='blue')\n",
    "    ax.plot(range(n, n + len(total_claims)), total_claims, 'o-', color='red')\n",
    "    return pd.DataFrame([{'uu_id': uu_id, 'predicted': total_claims, 'week_number': 41}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb70e4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_var_all(d, csv_name='results_var.csv'):    \n",
    "    r = d.groupby('uu_id').apply(run_var).reset_index(0, drop=True)\n",
    "    r.loc[r.predicted < 0, 'predicted'] = 0\n",
    "    r.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_var(get_subset(d, 1))\n",
    "# convert_to_submission('results_var.csv', week_number_to_submit=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a6abe",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def varmax(y, order, exog=None):\n",
    "    mod = sm.tsa.VARMAX(y, order=order, trend='n', enforce_invertibility=False, exog=exog\n",
    "            # enforce_stationarity=False,\n",
    "            )\n",
    "    results = mod.fit(maxiter=1000, disp=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b9443",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_varmax(g, plot=False):\n",
    "    g = g[['uu_id', 'week_number', 'date', 'total_claims'] + COL_MAP['edu'] + COL_MAP['race'] + COL_MAP['gender']]\n",
    "    uu_id = g.uu_id.values[0]\n",
    "    g.index = pd.DatetimeIndex(g.date)\n",
    "    g.index = pd.DatetimeIndex(g.index.values, freq=g.index.inferred_freq)\n",
    "    y = g.drop(['uu_id', 'week_number', 'date'], axis=1)\n",
    "    y = y.loc[:, (y != 0).any(axis=0)]\n",
    "    x = y.drop('total_claims', axis=1)\n",
    "    if y.shape[1] <= 2:\n",
    "        # total_claims = g.iloc[:, 0].values.mean()\n",
    "        pass\n",
    "    else:\n",
    "        results = varmax(y, (2, 0), exog=x)\n",
    "        predicted = results.get_prediction(start=week_number_to_date(30), end=week_number_to_date(41), dynamic=False).predicted_mean\n",
    "        if plot:\n",
    "            results.plot_diagnostics(figsize=(10, 7))\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(y.index, y.total_claims, 'o-')\n",
    "            ax.plot(predicted.index, predicted.total_claims, 'o-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe20aa6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_varmax(d):\n",
    "    for i in range(6):\n",
    "        g = get_subset(d, i)\n",
    "        run_varmax(g, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209bd61a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_train_test(g):\n",
    "    x = g[COL_MAP['edu'] + COL_MAP['race'] + COL_MAP['gender'] + ['week_number']]\n",
    "    y = g['total_claims']\n",
    "    last_week_number = x.week_number.max()\n",
    "    x_test_last = x.loc[x.week_number == last_week_number, :].copy()\n",
    "    x_test_last['week_number'] = last_week_number + 1\n",
    "    x_test = pd.concat([x, x_test_last], ignore_index=True)\n",
    "    return x, y, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e91d90",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_xgb_old(g, params={'n_estimators': 1000}):\n",
    "    uu_id = g.uu_id.values[0]\n",
    "    x, y, x_test = get_train_test(g)\n",
    "    reg = xgb.XGBRegressor(objective='reg:squarederror', **params)\n",
    "    reg.fit(x, y, verbose=True)\n",
    "    yhat = reg.predict(x_test)\n",
    "    x_test['predicted'] = yhat\n",
    "    x_test['uu_id'] = uu_id\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a47148b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def optimize_xgb(g):\n",
    "    uu_id = g.uu_id.values[0]\n",
    "    x, y, x_test = get_train_test(g)\n",
    "    # params = {\n",
    "    #     'min_child_weight': [1, 5, 10],\n",
    "    #     'gamma': [0.3, 0.5, 1.0, 1.5, 2.0, 5.0],\n",
    "    #     'subsample': [0.6, 0.8, 1.0],\n",
    "    #     'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    #     'max_depth': [2, 3, 4, 5],\n",
    "    #     'n_estimators': [300, 600, 1000],\n",
    "    #     'learning_rate': [0.001, 0.01, 0.1]\n",
    "    # }\n",
    "    params = {\n",
    "        'min_child_weight': [1],\n",
    "        'gamma': [0.3],\n",
    "        'subsample': [0.6, 0.8],\n",
    "        'colsample_bytree': [0.6, 0.8],\n",
    "        'max_depth': [3],\n",
    "        'n_estimators': [600, 1000],\n",
    "        # 'learning_rate': [0.3]\n",
    "    }\n",
    "    reg = xgb.XGBRegressor(nthread=-1, objective='reg:squarederror')\n",
    "    grid = sklearn.model_selection.GridSearchCV(reg, params)\n",
    "    grid.fit(x, y)\n",
    "    yhat = grid.best_estimator_.predict(x_test)\n",
    "    x_test['predicted'] = yhat\n",
    "    x_test['uu_id'] = uu_id\n",
    "    return x_test, grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e84fc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_xgb(d, n=6):    \n",
    "    fig, axs = plt.subplots(ncols=n, figsize=(18, 3), sharey=True)\n",
    "    for i in range(n):\n",
    "        ax = axs[i]\n",
    "        g = get_subset(d, i)        \n",
    "        pred = run_xgb_old(g)\n",
    "        # pred, best_score, best_params = optimize_xgb(g)\n",
    "        # print(i)\n",
    "        # print(f'best score: {best_score}')\n",
    "        # print('best_param: ', best_params)\n",
    "        ax.plot(g.week_number, g.total_claims, 'o-')\n",
    "        ax.plot(pred.week_number, pred.predicted, 'o-')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b586c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_xgb(d)\n",
    "# get_train_test(get_subset(d, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a031704",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_xgb_all(d, csv_name='results_xgb.csv'):\n",
    "    if os.path.isfile(csv_name):\n",
    "        return\n",
    "    l = []\n",
    "    for i, (uu_id, g) in enumerate(d.groupby('uu_id')):    \n",
    "        if i % 100 == 0:\n",
    "            print(f'processed {i} UUIDs')\n",
    "        predicted = run_xgb(g)\n",
    "        l.append(predicted)\n",
    "    df = pd.concat(l, ignore_index=True)\n",
    "    df.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bbbfae",
   "metadata": {},
   "source": [
    "run_xgb_all(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da18a7b6",
   "metadata": {},
   "source": [
    "convert_to_submission('results_xgb.csv', week_number_to_submit=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b9710",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot(d, n=6):\n",
    "    fig, axs = plt.subplots(ncols=n, sharey=True, figsize=(n*3, 3))\n",
    "    for i in range(n):\n",
    "        g = get_subset(d, i)\n",
    "        ax = axs[i]\n",
    "        ax.plot(g.week_number, g.total_claims, 'o-')\n",
    "        ax.set_xlim((0, 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2bed8c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_dummies(d, cols):\n",
    "    d_cat = pd.get_dummies(d.loc[:, cols])\n",
    "    d_others = d.drop(cols, axis=1)\n",
    "    d = pd.concat([d_others, d_cat], axis=1)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1637a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_train_test_xgb(g):\n",
    "    mask_train = g.week_number <= 30\n",
    "    mask_test = ~mask_train\n",
    "    # x_train = g.loc[mask_train, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382501d7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess_xgb(d):\n",
    "    d = d[get_cols(['total_claims', 'uu_id', 'average_wage', 'week_number'])].copy()\n",
    "    # d = get_dummies(d, COL_MAP['industry'])\n",
    "    d['date'] = d['week_number'].apply(week_number_to_date)\n",
    "    d['month'] = d['date'].dt.month\n",
    "    d['quarter'] = d['date'].dt.quarter\n",
    "    nlags = 3\n",
    "    d['mean_month'] = d.groupby('month')['total_claims'].transform(lambda x: float(x.dropna().mean()))\n",
    "    d['mean_quarter'] = d.groupby('quarter')['total_claims'].transform(lambda x: float(x.dropna().mean())) \n",
    "    \n",
    "    # for lag in range(1, nlags + 1):        \n",
    "    #     d[f'shift_{lag}'] = d.groupby('uu_id')['total_claims'].transform(lambda x: x.shift(lag))\n",
    "    \n",
    "    d = d.drop(['date'], axis=1)    \n",
    "    encoder = sklearn.preprocessing.LabelEncoder()\n",
    "    d['uu_id'] = encoder.fit_transform(d['uu_id'].astype(str))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f954a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_raw_full()\n",
    "# d = preprocess_xgb(d)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b499b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# from impyute.imputation.cs import mice\n",
    "import impyute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60515b80",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_mice(d):\n",
    "    cols_numeric = ['total_claims', 'average_wage', 'week_number']\n",
    "    d_numeric = d.loc[:, cols_numeric].astype('float64')\n",
    "    d_numeric_imputed = impyute.imputation.cs.mice(d_numeric.values)\n",
    "    d['total_claims_imputed'] = d_numeric_imputed[:, 0]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3215aa5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_impute(d, n=6):\n",
    "    fig, axs = plt.subplots(ncols=n, sharey=True, figsize=(n*3, 3))\n",
    "    for i in range(n):\n",
    "        g = get_subset(d, i)\n",
    "        ax = axs[i]\n",
    "        ax.plot(g.week_number, g.total_claims, 'o-', label='original')\n",
    "        ax.plot(g.week_number, g.total_claims_imputed, '--', label='imputed')\n",
    "        ax.set_xlim(0, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9751211",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_impute(impute_mice(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8aa4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_raw_full()\n",
    "d['total_claims_imputed'] = d['total_claims'].interpolate(method='linear')\n",
    "plot_impute(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['total_claims'] = d['total_claims'].interpolate(method='linear')\n",
    "d['date'] = d['week_number'].apply(week_number_to_date)\n",
    "if not os.path.isfile('results_arima_linear.csv'):\n",
    "    predict_all(d, 'total_claims', 'results_arima_linear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d26724",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "d['total_claims'] = d['total_claims'].interpolate(method='linear')\n",
    "d['date'] = d['week_number'].apply(week_number_to_date)\n",
    "if not os.path.isfile('results_arima_linear.csv'):\n",
    "    # predict_all(d, 'total_claims', 'results_arima_linear.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f00dd",
   "metadata": {},
   "source": [
    "d['total_claims'] = d['total_claims'].interpolate(method='linear')\n",
    "d['date'] = d['week_number'].apply(week_number_to_date)\n",
    "if not os.path.isfile('results_arima_linear.csv'):\n",
    "    predict_all(d, 'total_claims', 'results_arima_linear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c84e80",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_arima_linear(n=6):\n",
    "    d = load_raw_full()\n",
    "    r = pd.read_csv('results_arima_linear.csv')\n",
    "    fig, axs = plt.subplots(ncols=n, sharey=True, figsize=(n*3, 3))\n",
    "    for i in range(n):\n",
    "        ax = axs[i]\n",
    "        dd = get_subset(d, i)\n",
    "        rr = get_subset(r, i)\n",
    "        ax.plot(dd.week_number, dd.total_claims, 'o-', label='raw')\n",
    "        ax.plot(rr.week_number, rr.predicted, 'o-', label='predicted')\n",
    "        ax.set_xlim(0, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390a1b8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_arima_linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235f7b1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_arima_linear(n=6):\n",
    "    d = load_raw_full()\n",
    "    r = pd.read_csv('results_arima_linear.csv')\n",
    "    fig, axs = plt.subplots(ncols=n, sharey=True, figsize=(n*3, 3))\n",
    "    for i in range(n):\n",
    "        ax = axs[i]\n",
    "        dd = get_subset(d, i)\n",
    "        rr = get_subset(r, i)\n",
    "        ax.plot(dd.week_number, dd.total_claims, 'o-', label='raw')\n",
    "        ax.plot(rr.week_number, rr.predicted, 'o-', label='predicted')\n",
    "        ax.set_xlim(0, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48cf98",
   "metadata": {},
   "source": [
    "plot_arima_linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bd6af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be13a7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515237d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_prophet(g, period=0, growth='logistic', changepoint_range=0.8, n_changepoints=100, changepoint_prior_scale=0.75, seasonality_mode='additive', seasonality_prior_scale=10.0):\n",
    "    g = g.reset_index(0, drop=True)\n",
    "    gg = g.copy()\n",
    "    x = pd.DataFrame({'ds': gg['date'], 'y': np.log(gg['total_claims']), 'cap': np.log(gg['total_claims']).max()})\n",
    "    model = prophet.Prophet(\n",
    "        weekly_seasonality=False,\n",
    "        changepoint_range=changepoint_range,  \n",
    "        n_changepoints=n_changepoints, \n",
    "        changepoint_prior_scale=changepoint_prior_scale,\n",
    "        growth=growth,\n",
    "        seasonality_mode=seasonality_mode,\n",
    "        seasonality_prior_scale=seasonality_prior_scale,\n",
    "        )\n",
    "    if period:\n",
    "        model.add_seasonality(name='monthly', period=30, fourier_order=period)\n",
    "        model.add_seasonality(name='quarterly', period=90, fourier_order=period)\n",
    "        model.add_seasonality(name='yearly', period=365, fourier_order=period)\n",
    "    pred = model.fit(x).predict(x)\n",
    "    gg['predicted'] = np.exp(pred.yhat)\n",
    "    gg['predicted'] = gg['predicted'].clip(lower=0, upper=gg['total_claims'].max())\n",
    "    return gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d6bc0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_prophet(n=12):\n",
    "    d = load_raw_full()\n",
    "    ncols = 6\n",
    "    nrows = int(np.ceil(n/ncols))\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(3*ncols, 3*nrows), sharex=True)\n",
    "    for i in range(n):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        idx_row = int(i / ncols)\n",
    "        idx_col = i % ncols\n",
    "        if nrows == 1:\n",
    "            ax = axs[idx_col]\n",
    "        else:\n",
    "            ax = axs[idx_row, idx_col]\n",
    "        dd = get_subset(d, i)\n",
    "        ax.plot(dd.week_number, dd.total_claims, 'o', label='raw')\n",
    "        for growth in ['logistic', 'linear']:            \n",
    "            pred = run_prophet(dd,\n",
    "                growth=growth\n",
    "               )\n",
    "            ax.plot(pred.week_number, pred.predicted, '-', label=f'fb: {growth}')\n",
    "        if idx_row == 0 and idx_col == ncols - 1:\n",
    "            ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = load_raw_full()\n",
    "# run_prophet(get_subset(d, 6))\n",
    "plot_prophet(n=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca72615",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c56c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_prophet(g, period=0, growth='logistic', changepoint_range=0.8, n_changepoints=100, changepoint_prior_scale=0.75, seasonality_mode='additive', seasonality_prior_scale=10.0):\n",
    "    g = g.reset_index(0, drop=True)\n",
    "    gg = g.copy()\n",
    "    x = pd.DataFrame({'ds': gg['date'], 'y': np.log(gg['total_claims']), 'cap': np.log(gg['total_claims']).max()})\n",
    "    model = prophet.Prophet(\n",
    "        weekly_seasonality=False,\n",
    "        changepoint_range=changepoint_range,  \n",
    "        n_changepoints=n_changepoints, \n",
    "        changepoint_prior_scale=changepoint_prior_scale,\n",
    "        growth=growth,\n",
    "        seasonality_mode=seasonality_mode,\n",
    "        seasonality_prior_scale=seasonality_prior_scale,\n",
    "        )\n",
    "    if period:\n",
    "        model.add_seasonality(name='monthly', period=30, fourier_order=period)\n",
    "        model.add_seasonality(name='quarterly', period=90, fourier_order=period)\n",
    "        model.add_seasonality(name='yearly', period=365, fourier_order=period)\n",
    "    pred = model.fit(x).predict(x)\n",
    "    gg['predicted'] = np.exp(pred.yhat)\n",
    "    gg['predicted'] = gg['predicted'].clip(lower=0, upper=gg['total_claims'].max())\n",
    "    return gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f66f1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_prophet(n=12):\n",
    "    d = load_raw_full()\n",
    "    d = impute_mice(d)\n",
    "    d['total_claims'] = d['total_claims_imputed']\n",
    "    ncols = 6\n",
    "    nrows = int(np.ceil(n/ncols))\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(3*ncols, 3*nrows), sharex=True)\n",
    "    for i in range(n):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        idx_row = int(i / ncols)\n",
    "        idx_col = i % ncols\n",
    "        if nrows == 1:\n",
    "            ax = axs[idx_col]\n",
    "        else:\n",
    "            ax = axs[idx_row, idx_col]\n",
    "        dd = get_subset(d, i)\n",
    "        ax.plot(dd.week_number, dd.total_claims, 'o', label='raw')\n",
    "        for growth in ['logistic', 'linear']:            \n",
    "            pred = run_prophet(dd,\n",
    "                growth=growth\n",
    "               )\n",
    "            ax.plot(pred.week_number, pred.predicted, '-', label=f'fb: {growth}')\n",
    "        if idx_row == 0 and idx_col == ncols - 1:\n",
    "            ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = load_raw_full()\n",
    "# run_prophet(get_subset(d, 6))\n",
    "plot_prophet(n=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd3581",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ce590",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_prophet(g, period=0, growth='logistic', changepoint_range=0.8, n_changepoints=100, changepoint_prior_scale=0.75, seasonality_mode='additive', seasonality_prior_scale=10.0):\n",
    "    g = g.reset_index(0, drop=True)\n",
    "    gg = g.copy()\n",
    "    x = pd.DataFrame({'ds': gg['date'], 'y': np.log(gg['total_claims']), 'cap': np.log(gg['total_claims']).max()})\n",
    "    model = prophet.Prophet(\n",
    "        weekly_seasonality=False,\n",
    "        changepoint_range=changepoint_range,  \n",
    "        n_changepoints=n_changepoints, \n",
    "        changepoint_prior_scale=changepoint_prior_scale,\n",
    "        growth=growth,\n",
    "        seasonality_mode=seasonality_mode,\n",
    "        seasonality_prior_scale=seasonality_prior_scale,\n",
    "        )\n",
    "    if period:\n",
    "        model.add_seasonality(name='monthly', period=30, fourier_order=period)\n",
    "        model.add_seasonality(name='quarterly', period=90, fourier_order=period)\n",
    "        model.add_seasonality(name='yearly', period=365, fourier_order=period)\n",
    "    pred = model.fit(x).predict(x)\n",
    "    gg['predicted'] = np.exp(pred.yhat)\n",
    "    gg['predicted'] = gg['predicted'].clip(lower=0, upper=gg['total_claims'].max())\n",
    "    return gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d215c9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_prophet(n=12):\n",
    "    d = load_raw_full()\n",
    "    # d = impute_mice(d)\n",
    "    # d['total_claims'] = d['total_claims_imputed']\n",
    "    d['total_claims'] = d['total_claims'].interpolate(method='linear')\n",
    "    ncols = 6\n",
    "    nrows = int(np.ceil(n/ncols))\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(3*ncols, 3*nrows), sharex=True)\n",
    "    for i in range(n):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        idx_row = int(i / ncols)\n",
    "        idx_col = i % ncols\n",
    "        if nrows == 1:\n",
    "            ax = axs[idx_col]\n",
    "        else:\n",
    "            ax = axs[idx_row, idx_col]\n",
    "        dd = get_subset(d, i)\n",
    "        ax.plot(dd.week_number, dd.total_claims, 'o', label='raw')\n",
    "        for growth in ['logistic', 'linear']:            \n",
    "            pred = run_prophet(dd,\n",
    "                growth=growth\n",
    "               )\n",
    "            ax.plot(pred.week_number, pred.predicted, '-', label=f'fb: {growth}')\n",
    "        if idx_row == 0 and idx_col == ncols - 1:\n",
    "            ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e67555",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# d = load_raw_full()\n",
    "# run_prophet(get_subset(d, 6))\n",
    "plot_prophet(n=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484e1cf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_prophet_all(csv_name='results_prophet.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        d = load_raw_full()\n",
    "        d['total_claims'] = d['total_claims'].interpolate(method='linear')\n",
    "        l = []\n",
    "        for i, (uu_id, g) in enumerate(d.groupby('uu_id')):\n",
    "            if i % 20 == 0:\n",
    "                print(i)\n",
    "            r = run_prophet(g)\n",
    "            l.append(r)\n",
    "        pred = pd.concat(l, ignore_index=True)\n",
    "        pred.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dcc515",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prophet_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf105ae0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "convert_to_submission('results_prophet.csv', week_number_to_submit=43)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
