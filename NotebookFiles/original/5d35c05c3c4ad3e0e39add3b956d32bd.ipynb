{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e8f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"%logstop\\n%logstart -t -r -q ipython_command_log.py global\\n\\n#- IRONHACKS RESEARCH TRACKING CODE\\n#----------------------------------\\n# The following code is used to help our research team understand how you \\n# our notebook environment. We do not collect any personal information with\\n# the following code, it is used to measure when and how often you work on\\n# your submission files.\\n\\nimport os\\nfrom datetime import datetime\\nimport IPython.core.history as history\\n\\nha = history.HistoryAccessor()\\nha_tail = ha.get_tail(1)\\nha_cmd = next(ha_tail)\\nsession_id = str(ha_cmd[0])\\ncommand_id = str(ha_cmd[1])\\ntimestamp = datetime.utcnow().isoformat()\\nhistory_line = ','.join([session_id, command_id, timestamp]) + '\\\\n'\\nlogfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\\nlogfile.write(history_line)\\nlogfile.close()\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74062355",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"#- INSTALL ADDITIONAL LIBRARIES IF REQUIRED\\n#------------------------------------------\\n# This is normally not required. The hub environment comes preinstaled with \\n# many packages that you can already use without setup. In case there is some\\n# other library you would like to use that isn't on the list you run this command\\n# once to install them.  If it is already installed this command has no effect.\\n!pip install google-cloud-bigquery\\n!pip install google-cloud-bigquery[pandas]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a536dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- IMPORT THE LIBRARIES YOU WILL USE\n",
    "#------------------------------------------\n",
    "# You only need to import packages one time per notebook session. To keep your\n",
    "# notebook clean and organized you can handle all imports at the top of your file.\n",
    "# The following are included for example purposed, feel free to modify or delete \n",
    "# anything in this section.\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1db425",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGQUERY_PROJECT = 'ironhacks-data'\n",
    "bigquery_client = bigquery.Client(project=BIGQUERY_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e04c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query 3: overview of employment_data(week 41)\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.unemployment_data`\n",
    "ORDER BY week_number ASC;\n",
    "\"\"\"\n",
    "query_job = bigquery_client.query(query)\n",
    "overview = query_job.to_dataframe()\n",
    "overview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddfb5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query 2: overview of important info from unemployment table\n",
    "query = \"\"\"\n",
    "SELECT uu_id, week_number, total_claims\n",
    "FROM `ironhacks-data.ironhacks_competition.unemployment_data` \n",
    "ORDER BY week_number ASC\n",
    "\"\"\"\n",
    "query_jobb = bigquery_client.query(query)\n",
    "employ = query_jobb.to_dataframe()\n",
    "print(employ.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ce7ce",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#query 3: overview of prediction list (week 41)\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.prediction_list`\n",
    "\"\"\"\n",
    "query_job = bigquery_client.query(query)\n",
    "predn = query_job.to_dataframe()\n",
    "predn.head()\n",
    "print(predn.head())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
