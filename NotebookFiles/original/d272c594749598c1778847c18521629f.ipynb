{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475e307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"%logstop\\n%logstart -t -r -q ipython_command_log.py global\\nimport os\\nfrom datetime import datetime\\nimport IPython.core.history as history\\n\\nha = history.HistoryAccessor()\\nha_tail = ha.get_tail(1)\\nha_cmd = next(ha_tail)\\nsession_id = str(ha_cmd[0])\\ncommand_id = str(ha_cmd[1])\\ntimestamp = datetime.utcnow().isoformat()\\nhistory_line = ','.join([session_id, command_id, timestamp]) + '\\\\n'\\nlogfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\\nlogfile.write(history_line)\\nlogfile.close()\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', '!pip install google-cloud-bigquery\\n!pip install google-cloud-bigquery[pandas]\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- IMPORT THE LIBRARIES YOU WILL USE\n",
    "#------------------------------------------\n",
    "# You only need to import packages one time per notebook session. To keep your\n",
    "# notebook clean and organized you can handle all imports at the top of your file.\n",
    "# The following are included for example purposed, feel free to modify or delete \n",
    "# anything in this section.\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba0a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGQUERY_PROJECT = 'ironhacks-data'\n",
    "bigquery_client = bigquery.Client(project=BIGQUERY_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60912edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query 3: overview of employment_data(week 41)\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.unemployment_data`\n",
    "ORDER BY week_number ASC;\n",
    "\"\"\"\n",
    "query_job = bigquery_client.query(query)\n",
    "overview = query_job.to_dataframe()\n",
    "overview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921168aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query 2: overview of important info from unemployment table\n",
    "query = \"\"\"\n",
    "SELECT uu_id, week_number, total_claims\n",
    "FROM `ironhacks-data.ironhacks_competition.unemployment_data` \n",
    "ORDER BY week_number ASC\n",
    "\"\"\"\n",
    "query_jobb = bigquery_client.query(query)\n",
    "employ = query_jobb.to_dataframe()\n",
    "print(employ.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query 3: overview of prediction list (week 41)\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.prediction_list`\n",
    "\"\"\"\n",
    "query_job = bigquery_client.query(query)\n",
    "predn = query_job.to_dataframe()\n",
    "predn.head()\n",
    "print(predn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([employ.week_number], [employ.total_claims],'bs')\n",
    "plt.title('Distribution of claims through week')\n",
    "plt.xlabel('Weeks')\n",
    "plt.ylabel('Total claims')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d805b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(overview['total_claims'])\n",
    "features = employ.drop(['uu_id'], axis=1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ccb630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test sets, split first 20% data\n",
    "x_train, x_test, y_train,y_test = train_test_split(features, labels, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training Features Shape: {x_train.shape}')\n",
    "print(f'Testing Features Shape: {x_test.shape}')\n",
    "print(f'Training Labels Shape: {y_train.shape}')\n",
    "print(f'Testing Labels Shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
    "x = x_train\n",
    "y = y_train\n",
    "regressor.fit(x,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04042ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the decision tree from the regressor\n",
    "from sklearn import tree\n",
    "tree.plot_tree(regressor.estimators_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf2203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shown detailed status of decision tree\n",
    "from sklearn.datasets import make_regression\n",
    "x,y = make_regression(n_features=4, n_informative=2,\n",
    "                       random_state=0, shuffle=False)\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec0c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regr.predict([[0, 0, 0, 0]]))\n",
    "tree.plot_tree(regr.estimators_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regressor.predict(test_features).astype(int)\n",
    "predictions = np.round(predictions,decimals = 0, out = None)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209847ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regressor.predict(x_test).astype(int)\n",
    "predictions = np.round(predictions,decimals = 0, out = None)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = abs(y_test - predictions)\n",
    "print(f'List of Errors: {errors}')\n",
    "print(f'Mean Absolute Error: {np.mean(errors)*10:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53952e2",
   "metadata": {},
   "source": [
    "as the mean absolute error is less than 10%, we could take prediction as final outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab0e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions, columns=['total_claims'])\n",
    "week41 = predn.join(df).iloc[:,[0,2,1]]\n",
    "print(week41)\n",
    "print(f'Total predicting number of unemployment claims of week 41: {sum(predictions):.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4730149",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = week41.to_csv(\"submission_prediction_output.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c378118b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"%logstop\\n%logstart -t -r -q ipython_command_log.py global\\n\\n#- IRONHACKS RESEARCH TRACKING CODE\\n#----------------------------------\\n# The following code is used to help our research team understand how you \\n# our notebook environment. We do not collect any personal information with\\n# the following code, it is used to measure when and how often you work on\\n# your submission files.\\n\\nimport os\\nfrom datetime import datetime\\nimport IPython.core.history as history\\n\\nha = history.HistoryAccessor()\\nha_tail = ha.get_tail(1)\\nha_cmd = next(ha_tail)\\nsession_id = str(ha_cmd[0])\\ncommand_id = str(ha_cmd[1])\\ntimestamp = datetime.utcnow().isoformat()\\nhistory_line = ','.join([session_id, command_id, timestamp]) + '\\\\n'\\nlogfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\\nlogfile.write(history_line)\\nlogfile.close()\\n\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
