{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f0c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', '!pip install db-dtypes\\n!pip install keras\\n!pip install tensorflow\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86668a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"%logstop\\n%logstart -t -r -q ipython_command_log.py global\\n\\n#- IRONHACKS RESEARCH TRACKING CODE\\n#----------------------------------\\n# The following code is used to help our research team understand how you \\n# our notebook environment. We do not collect any personal information with\\n# the following code, it is used to measure when and how often you work on\\n# your submission files.\\n\\nimport os\\nfrom datetime import datetime\\nimport IPython.core.history as history\\n\\nha = history.HistoryAccessor()\\nha_tail = ha.get_tail(1)\\nha_cmd = next(ha_tail)\\nsession_id = str(ha_cmd[0])\\ncommand_id = str(ha_cmd[1])\\ntimestamp = datetime.utcnow().isoformat()\\nhistory_line = ','.join([session_id, command_id, timestamp]) + '\\\\n'\\nlogfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\\nlogfile.write(history_line)\\nlogfile.close()\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15298e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', 'import pandas as pd\\nimport numpy as np\\nimport os\\nfrom google.cloud import bigquery\\nfrom google.oauth2 import service_account\\nfrom google.cloud.bigquery import magics\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.svm import SVR\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.linear_model import LassoCV\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.linear_model import BayesianRidge\\nfrom sklearn.linear_model import ElasticNetCV\\nfrom keras.models import Sequential\\nfrom keras.layers import Bidirectional, LSTM, Dropout, Dense\\nfrom keras.models import load_model\\nimport joblib\\nfrom joblib import Parallel, delayed\\nfrom scipy import stats\\nfrom sklearn.ensemble import IsolationForest\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aed9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGQUERY_PROJECT = 'ironhacks-data'\n",
    "bigquery_client = bigquery.Client(project=BIGQUERY_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83deac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_main = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.unemployment_data`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40982f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bigquery_client.query(query_main)\n",
    "unemployment_data = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a79e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.wage_data`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bigquery_client.query(query)\n",
    "wage_data = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54df0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_pred = \"\"\"\n",
    "SELECT * \n",
    "FROM `ironhacks-data.ironhacks_competition.prediction_list`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8111637c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "query_job = bigquery_client.query(query_pred)\n",
    "prediction_list = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8679b7ab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_regressor(prediction_dataframe):\n",
    "    # Takes in a prediction dataframe of 2 columns, Actual values and Predicted values generated by a regressor\n",
    "    # Outputs MSE, MAR, RMSE and MAPE metrics. Must have columns named Actual and Predicted.\n",
    "    print('MSE:', mean_squared_error(prediction_dataframe['Actual'], prediction_dataframe['Predicted']))\n",
    "    print('MAE:', mean_absolute_error(prediction_dataframe['Actual'], prediction_dataframe['Predicted']))\n",
    "    print('RMSE:', np.sqrt(mean_squared_error(prediction_dataframe['Actual'], prediction_dataframe['Predicted'])))\n",
    "    print('MAPE:', np.mean(np.abs((prediction_dataframe['Actual'] - prediction_dataframe['Predicted']) / prediction_dataframe['Actual'])) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b3412",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_predictions(regressor, model_type, name, week):\n",
    "    # generates predictions for any model and writes out a dataframe in csv containing them\n",
    "    # takes a regressor and learning method type as input: DL and ML\n",
    "    # DL/ML variable basically changes the shape for an input from a 2D array to 3D arry, as required tensor shape\n",
    "    result_list = []\n",
    "    uu_id_transform = LE.fit_transform(prediction_list['uu_id'])\n",
    "    if model_type == 'DL':\n",
    "        predict_arr = np.array(SC_other.transform([[-0.04, -0.140, 0.328, -0.671, -0.420, -0.432, -0.0013, -0.0023, -0.347, -0.0004, 3.211, -0.532, -0.329]]))\n",
    "        for val in uu_id_transform:\n",
    "            to_predict = np.insert(predict_arr, 0, val, axis=1)\n",
    "            to_predict = np.insert(to_predict, 1, week, axis=1)\n",
    "            to_predict = np.reshape(to_predict, (to_predict.shape[0], to_predict.shape[1],1))\n",
    "            r = regressor.predict(to_predict)\n",
    "            result_list.append(r)\n",
    "        result_list = np.array(result_list)\n",
    "        result_list = np.reshape(result_list, (525,))\n",
    "    elif model_type == 'ML':\n",
    "        predict_arr = np.array(RB_other.transform([[-0.04, -0.140, 0.328, -0.671, -0.420, -0.432, -0.0013, -0.0023, -0.347, -0.0004, 3.211, -0.532, -0.329]]))\n",
    "        for val in uu_id_transform:\n",
    "            to_predict = np.insert(predict_arr, 0, val, axis=1)\n",
    "            to_predict = np.insert(to_predict, 1, week, axis=1)\n",
    "            r = regressor.predict(to_predict)\n",
    "            result_list.append(r)\n",
    "    result_df = pd.DataFrame(result_list, columns = ['Predictions'])\n",
    "    prediction_sub = prediction_list.copy()\n",
    "    prediction_sub['total_claims'] = result_df.values\n",
    "    prediction_sub = prediction_sub[['uu_id','total_claims','week_number']]\n",
    "    os.makedirs('lost+found/submission_files', exist_ok=True)\n",
    "    prediction_sub.to_csv('lost+found/submission_files/'+name+'.csv', index=False)\n",
    "    return prediction_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050aa14",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_pred_frame(test_frame, prediction_array):\n",
    "    prediction_frame = pd.DataFrame({'Actual': test_frame, 'Predicted': prediction_array.flatten()})\n",
    "    return prediction_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0ce59",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def clearOutlier_IQR(data):\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    no_outliers = data[~((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    print(no_outliers.shape)\n",
    "    return no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e175164",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# outlier detection and handling - Z Score (gaussian only)\n",
    "def clearOutlier_ZScore(data, threshold):\n",
    "    zscore = np.abs(stats.zscore(data))\n",
    "    thresh = threshold\n",
    "    no_outliers = data[(zscore < thresh).all(axis=1)]\n",
    "    return no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf5e2f1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# outlier detection - automatic\n",
    "def IsoForest_anomaly(data):\n",
    "    IFO = IsolationForest(random_state=69)\n",
    "    col_list = ['week_number', 'total_claims', 'edu_8th_or_less',\n",
    "                'edu_grades_9_11', 'edu_hs_grad_equiv', 'edu_post_hs', 'gender_female',\n",
    "                'gender_male', 'race_amerindian', 'race_asian', 'race_black',\n",
    "                'race_hawaiiannative', 'race_other', 'race_white', 'average_wage']\n",
    "    NO_df = data.copy()\n",
    "    IFO.fit(data)\n",
    "    NO_df['anomaly_scores'] = IFO.decision_function(data)\n",
    "    NO_df['anomaly'] = IFO.predict(data)\n",
    "    no_outlier = NO_df[NO_df['anomaly'] == 1]\n",
    "    print('Removed ', NO_df[NO_df['anomaly'] == -1].shape[0], 'datapoints')\n",
    "    palette = ['#ff7f0e','#1f77b4']\n",
    "    sns.pairplot(NO_df, vars = col_list, hue='anomaly', palette=palette)\n",
    "    no_outlier.drop(['anomaly_scores','anomaly'], axis = 1, inplace=True)\n",
    "    return no_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e4f2c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess(data, scaling):\n",
    "    no_outlierDF = ingest.copy()\n",
    "    to_drop = ['timeperiod','tract','top_category_employer1','top_category_employer2',\n",
    "           'top_category_employer3','tract_name','countyfips', 'edu_unknown', 'gender_na', \n",
    "           'race_noanswer']\n",
    "    to_scale = ['edu_8th_or_less', 'edu_grades_9_11', 'edu_hs_grad_equiv', 'edu_post_hs', \n",
    "            'gender_female', 'gender_male', 'race_amerindian', 'race_asian', 'race_black', \n",
    "            'race_hawaiiannative', 'race_other', 'race_white', 'average_wage']\n",
    "    no_outlierDF.drop(to_drop, axis=1, inplace=True)\n",
    "    no_outlierDF['uu_id'] = LE.fit_transform(no_outlierDF['uu_id'])\n",
    "    if scaling == 'Robust':\n",
    "        no_outlierDF[to_scale] = RB_other.fit_transform(no_outlierDF[to_scale])\n",
    "    elif scaling == 'Standard':\n",
    "        no_outlierDF[to_scale] = SC_other.fit_transform(no_outlierDF[to_scale])\n",
    "    return no_outlierDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated_ingest = pd.concat([merged_ingest, combined_ingest])\n",
    "ingest = pd.read_csv('lost+found/submission_files/complete_ingest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73959a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick preprocess to keep uu_id and scale values\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler\n",
    "LE = LabelEncoder()\n",
    "RB_other = RobustScaler()\n",
    "SC_other = StandardScaler()\n",
    "# RB_claims = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c55ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_data = preprocess(ingest, 'Robust')\n",
    "ingest_clean = IsoForest_anomaly(ML_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d115c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target and independent variables\n",
    "Y = ingest_clean['total_claims']\n",
    "X = ingest_clean[['uu_id', 'week_number', 'edu_8th_or_less',\n",
    "                 'edu_grades_9_11', 'edu_hs_grad_equiv', 'edu_post_hs', 'gender_female',\n",
    "                 'gender_male', 'race_amerindian', 'race_asian', 'race_black',\n",
    "                 'race_hawaiiannative', 'race_other', 'race_white', 'average_wage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.20, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model - next time, I'll need to learn to use PMML\n",
    "RFR_Regressor = joblib.load('RF_v1-7.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b951ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_RFR = RFR_Regressor.predict(X_test.values).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "evaluate_regressor(get_pred_frame(Y_test,Y_pred_RFR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call func\n",
    "get_predictions(RFR_Regressor, 'ML', 'submission_prediction_output_RFR', 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321be2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(Y_test.values, color = 'red', label = 'Actual values')\n",
    "plt.plot(Y_pred_RFR, color='blue', label='Predicted values')\n",
    "plt.title('Model Prediction Visual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17630392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this needs different feature engineering, so I'm starting from scratch\n",
    "DL_data = preprocess(ingest, 'Standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a308a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_ingest = IsoForest_anomaly(DL_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955336af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split set\n",
    "DL_Y = DL_ingest['total_claims']\n",
    "DL_X = DL_ingest[['uu_id', 'week_number', 'edu_8th_or_less', 'edu_grades_9_11', 'edu_hs_grad_equiv', 'edu_post_hs', 'gender_female', 'gender_male',\n",
    "               'race_amerindian', 'race_asian', 'race_black', 'race_hawaiiannative', 'race_other', 'race_white', 'average_wage']]\n",
    "DL_XTrain, DL_XTest, DL_YTrain, DL_YTest = train_test_split(DL_X, DL_Y, test_size=0.20, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4099e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to np vectors\n",
    "DL_XTrain = DL_XTrain.to_numpy()\n",
    "DL_XTest = DL_XTest.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ef52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape because F*** tensors\n",
    "DL_XTrain = np.reshape(DL_XTrain, (DL_XTrain.shape[0], DL_XTrain.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cd4262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert X and Y train to float because input dtype accepts floats only\n",
    "DL_YTrain = DL_YTrain.astype(float)\n",
    "DL_XTrain = DL_XTrain.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd275127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "StackLSTM_Regressor = load_model('BiDLSTM_v1-05.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad79962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary for viewers\n",
    "StackLSTM_Regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c79a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float cast\n",
    "DL_XTest = DL_XTest.astype(float)\n",
    "# make predictions\n",
    "DL_XTest = np.reshape(DL_XTest, (DL_XTest.shape[0], DL_XTest.shape[1],1))\n",
    "predictions = StackLSTM_Regressor.predict(DL_XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d759c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred_frame(DL_YTest, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_regressor(get_pred_frame(DL_YTest, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(DL_YTest.values, color = 'red', label = 'Actual values')\n",
    "plt.plot(predictions, color='blue', label='Predicted values')\n",
    "plt.title('Model Prediction Visual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ce87e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "get_predictions(StackLSTM_Regressor, 'DL', 'submission_prediction_output', 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee44ef5b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_predictions(regressor, model_type, name, week):\n",
    "    # generates predictions for any model and writes out a dataframe in csv containing them\n",
    "    # takes a regressor and learning method type as input: DL and ML\n",
    "    # DL/ML variable basically changes the shape for an input from a 2D array to 3D arry, as required tensor shape\n",
    "    result_list = []\n",
    "    uu_id_transform = LE.fit_transform(prediction_list['uu_id'])\n",
    "    if model_type == 'DL':\n",
    "        predict_arr = np.array(SC_other.transform([[0, 1, 6, 4, 4, 5, 0, 1, 2, 0, 4, 1, 4200.0]]))\n",
    "        for val in uu_id_transform:\n",
    "            to_predict = np.insert(predict_arr, 0, val, axis=1)\n",
    "            to_predict = np.insert(to_predict, 1, week, axis=1)\n",
    "            to_predict = np.reshape(to_predict, (to_predict.shape[0], to_predict.shape[1],1))\n",
    "            r = regressor.predict(to_predict)\n",
    "            result_list.append(r)\n",
    "        result_list = np.array(result_list)\n",
    "        result_list = np.reshape(result_list, (525,))\n",
    "    elif model_type == 'ML':\n",
    "        predict_arr = np.array(RB_other.transform([[0, 1, 6, 4, 4, 5, 0, 1, 2, 0, 4, 1, 4200.0]]))\n",
    "        for val in uu_id_transform:\n",
    "            to_predict = np.insert(predict_arr, 0, val, axis=1)\n",
    "            to_predict = np.insert(to_predict, 1, week, axis=1)\n",
    "            r = regressor.predict(to_predict)\n",
    "            result_list.append(r)\n",
    "    result_df = pd.DataFrame(result_list, columns = ['Predictions'])\n",
    "    prediction_sub = prediction_list.copy()\n",
    "    prediction_sub['total_claims'] = result_df.values\n",
    "    prediction_sub = prediction_sub[['uu_id','total_claims','week_number']]\n",
    "    os.makedirs('lost+found/submission_files', exist_ok=True)\n",
    "    prediction_sub.to_csv('lost+found/submission_files/'+name+'.csv', index=False)\n",
    "    return prediction_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call func\n",
    "get_predictions(RFR_Regressor, 'ML', 'submission_prediction_output_RFR', 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred_frame(DL_YTest, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518b2878",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_regressor(get_pred_frame(DL_YTest, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494383f5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "get_predictions(StackLSTM_Regressor, 'DL', 'submission_prediction_output', 44)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
