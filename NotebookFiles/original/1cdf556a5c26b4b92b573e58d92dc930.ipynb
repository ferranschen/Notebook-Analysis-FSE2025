{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf7184",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', \"%logstop\\n%logstart -t -r -q ipython_command_log.py global\\n\\n#- IRONHACKS RESEARCH TRACKING CODE\\n#----------------------------------\\n# The following code is used to help our research team understand how you \\n# our notebook environment. We do not collect any personal information with\\n# the following code, it is used to measure when and how often you work on\\n# your submission files.\\n\\nimport os\\nfrom datetime import datetime\\nimport IPython.core.history as history\\n\\nha = history.HistoryAccessor()\\nha_tail = ha.get_tail(1)\\nha_cmd = next(ha_tail)\\nsession_id = str(ha_cmd[0])\\ncommand_id = str(ha_cmd[1])\\ntimestamp = datetime.utcnow().isoformat()\\nhistory_line = ','.join([session_id, command_id, timestamp]) + '\\\\n'\\nlogfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\\nlogfile.write(history_line)\\nlogfile.close()\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e80d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system('pip install db-dtypes')\n",
    "get_ipython().system('pip install xgboost')\n",
    "get_ipython().system('pip install prophet')\n",
    "get_ipython().system('pip install plotly')\n",
    "get_ipython().system('pip install plotly-geo')\n",
    "get_ipython().system('pip install geopandas')\n",
    "get_ipython().system('pip install pyshp')\n",
    "get_ipython().system('pip install shapely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd49214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory\n",
    "import plotly.subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e266bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import sklearn.experimental.enable_iterative_imputer\n",
    "import sklearn.impute\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737fe1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad83514",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300d01b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# define relevant columns based on categories \n",
    "COL_MAP = {\n",
    "    'edu': ['edu_8th_or_less', 'edu_grades_9_11', 'edu_hs_grad_equiv', 'edu_post_hs', 'edu_unknown'],\n",
    "    'race': ['race_amerindian', 'race_asian', 'race_black', 'race_noanswer', 'race_hawaiiannative', 'race_other', 'race_white'],    \n",
    "    'gender': ['gender_female', 'gender_male', 'gender_na'],\n",
    "    'industry': ['top_category_employer1', 'top_category_employer2', 'top_category_employer3']        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073ce9e7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_cols(names):\n",
    "    l = []\n",
    "    for name in names:\n",
    "        if name in COL_MAP:\n",
    "            l += COL_MAP[name]\n",
    "        else:\n",
    "            l += [name]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c8e4bc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def subset(df, uu_id_idx):        \n",
    "    return df.loc[df.uu_id == df.uu_id.unique()[uu_id_idx], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d5e16",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def convert_to_submission(results_csv, week_number_to_submit=40):\n",
    "    r = pd.read_csv(results_csv)\n",
    "    last = r.loc[r.week_number == week_number_to_submit, ['uu_id', 'predicted']]\n",
    "    last.index = last.uu_id\n",
    "    uuid_map = last.to_dict(orient='dict')['predicted']\n",
    "    p = query('prediction_list')\n",
    "    p['total_claims'] = p['uu_id'].map(uuid_map)\n",
    "    p.to_csv('submission_prediction_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24705ee",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_county(tract_name):\n",
    "    m = re.search('Census Tract \\S+, (.+) County, Indiana', tract_name)\n",
    "    county = m.group(1)\n",
    "    return county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442e043",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def query(table):\n",
    "    bigquery_client = bigquery.Client(project='ironhacks-data')\n",
    "    query_str = f'''\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_competition.{table}`\n",
    "'''\n",
    "    query_job = bigquery_client.query(query_str)\n",
    "    data = query_job.to_dataframe()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c1c6b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def combine(u, w):\n",
    "    '''\n",
    "    Joins the unemployment data and the wage data on `uu_id`\n",
    "    '''\n",
    "    ww = w.loc[:, ['uu_id', 'average_wage']]\n",
    "    d = u.join(ww.set_index('uu_id'), on='uu_id')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f517fd6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_raw(csv_name='0_raw.csv'):\n",
    "    '''\n",
    "    Loads the unemployment and wage data and does some basic cleaning\n",
    "    '''\n",
    "    if not os.path.isfile(csv_name):\n",
    "        u = query('unemployment_data')\n",
    "        w = query('wage_data')\n",
    "        raw = combine(u, w)\n",
    "        raw.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        raw = pd.read_csv(csv_name)\n",
    "    raw['county'] = raw['tract_name'].apply(get_county)\n",
    "    raw = raw.drop(['tract', 'timeperiod', 'tract_name'], axis=1)\n",
    "    raw = raw.sort_values(by=['uu_id', 'week_number'])\n",
    "    raw = raw.drop_duplicates()\n",
    "    raw = raw.replace({np.nan: None})\n",
    "    raw = raw.reset_index(0, drop=True)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94afbfd6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "load_raw().to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85ad02",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_week_number_map(g, colname):\n",
    "    '''\n",
    "    Creates a dictionary that maps from week number to an existing value in a given `colname`\n",
    "    '''\n",
    "    g = g[['week_number', colname]]\n",
    "    week_number_map = dict(sorted(g.values.tolist()))\n",
    "    return week_number_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea597a8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def week_number_to_date(week_number, first_week_date='20220101'):\n",
    "    '''\n",
    "    Prepare a date column for ARIMA\n",
    "    '''\n",
    "    return pd.to_datetime(first_week_date, format='%Y%m%d') + pd.DateOffset(days=7*(week_number - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fdc71b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def insert_na_week_number(g, min_week_number='min', max_week_number=37):\n",
    "    d = {}\n",
    "    if min_week_number == 'min':\n",
    "        week_number_min = g.week_number.min()\n",
    "    else:\n",
    "        week_number_min = min_week_number\n",
    "    for colname in g.columns:\n",
    "        week_number_map = get_week_number_map(g, colname)\n",
    "        series = pd.Series(range(week_number_min, max_week_number+1))        \n",
    "        d[colname] = series.map(week_number_map)        \n",
    "    \n",
    "    df = pd.DataFrame(d)\n",
    "    df['week_number'] = range(week_number_min, max_week_number+1)\n",
    "    df['uu_id'] = [v for v in df['uu_id'].unique() if type(v) == str][0]\n",
    "    df['average_wage'] = [v for v in g['average_wage'].unique()][0]\n",
    "    df['countyfips'] = [v for v in g['countyfips'].unique()][0]\n",
    "    df['county'] = [v for v in g['county'].unique() if type(v) == str][0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a1aa4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_raw_full(csv_name='1_raw_full.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        raw = load_raw()\n",
    "        raw_full = raw.groupby('uu_id').apply(insert_na_week_number).reset_index(0, drop=True)\n",
    "        raw_full['date'] = raw_full['week_number'].apply(week_number_to_date)        \n",
    "        raw_full.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        raw_full = pd.read_csv(csv_name)\n",
    "    return raw_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df43009",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_raw_full()[['uu_id', 'week_number', 'total_claims']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a35ad2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d5b3a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_prophet(g, period=0, growth='linear', changepoint_range=0.8, n_changepoints=100, changepoint_prior_scale=0.75, seasonality_mode='additive', seasonality_prior_scale=10.0):\n",
    "    g = g.reset_index(0, drop=True)\n",
    "    gg = g.copy()\n",
    "    x = pd.DataFrame({'ds': gg['date'], 'y': np.log(gg['total_claims']), 'cap': np.log(gg['total_claims']).max()})\n",
    "    model = prophet.Prophet(\n",
    "        weekly_seasonality=False,\n",
    "        changepoint_range=changepoint_range,  \n",
    "        n_changepoints=n_changepoints, \n",
    "        changepoint_prior_scale=changepoint_prior_scale,\n",
    "        growth=growth,\n",
    "        seasonality_mode=seasonality_mode,\n",
    "        seasonality_prior_scale=seasonality_prior_scale,\n",
    "        )\n",
    "    if period:\n",
    "        model.add_seasonality(name='monthly', period=30, fourier_order=period)\n",
    "        model.add_seasonality(name='quarterly', period=90, fourier_order=period)\n",
    "        model.add_seasonality(name='yearly', period=365, fourier_order=period)\n",
    "    pred = model.fit(x).predict(x)\n",
    "    gg['predicted'] = np.exp(pred.yhat)\n",
    "    gg['predicted'] = gg['predicted'].clip(lower=0, upper=gg['total_claims'].max())\n",
    "    gg['total_claims_imputed'] = gg['total_claims'].fillna(gg['predicted'])\n",
    "    return gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0fbf0d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_prophet(n=12):\n",
    "    d = load_raw_full()\n",
    "    ncols = 6\n",
    "    nrows = int(np.ceil(n/ncols))\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(3*ncols, 3*nrows), sharex=True)\n",
    "    for i in range(n):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        idx_row = int(i / ncols)\n",
    "        idx_col = i % ncols\n",
    "        if nrows == 1:\n",
    "            ax = axs[idx_col]\n",
    "        else:\n",
    "            ax = axs[idx_row, idx_col]\n",
    "        dd = subset(d, i)\n",
    "        ax.plot(dd.week_number, dd.total_claims, 'o', label='raw')\n",
    "        for growth in ['logistic', 'linear']:            \n",
    "            pred = run_prophet(dd, growth=growth)\n",
    "            pp = pred.loc[pred.total_claims.isna(), :]\n",
    "            ax.plot(pp.week_number, pp.predicted, 'o', label=f'fb: {growth}')\n",
    "        if idx_row == 0 and idx_col == ncols - 1:\n",
    "            ax.legend()\n",
    "        if idx_row == nrows - 1:\n",
    "            ax.set_xlabel('week_number')\n",
    "        if idx_col == 0:\n",
    "            ax.set_ylabel('claims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405601b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_prophet(n=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e63579",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_imp_tot(csv_name='2_imp_tot.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        raw = load_raw_full()\n",
    "        l = []\n",
    "        for i, (uu_id, g) in enumerate(raw.groupby('uu_id')):\n",
    "            if i % 20 == 0:\n",
    "                print(i)\n",
    "            gg = run_prophet(g, growth='linear')\n",
    "            gg['total_claims'] = gg['total_claims_imputed']\n",
    "            l.append(gg)\n",
    "        d = pd.concat(l, ignore_index=True)\n",
    "        d = d.drop(['predicted', 'total_claims_imputed'], axis=1)\n",
    "        d.to_csv(csv_name, index=False)        \n",
    "    else:\n",
    "        d = pd.read_csv(csv_name)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee85cba",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_impute(n=6):\n",
    "    raw = load_raw_full()\n",
    "    imp = load_imp_tot()\n",
    "    fig, axs = plt.subplots(ncols=n, sharey=False, figsize=(n*3, 3))\n",
    "    for i in range(n):\n",
    "        rraw = subset(raw, i)\n",
    "        iimp = subset(imp, i)\n",
    "        ax = axs[i]\n",
    "        ax.plot(rraw.week_number, rraw.total_claims, 'o', label='original')\n",
    "        ax.plot(iimp.week_number, iimp.total_claims, '-', label='imputed')\n",
    "        ax.set_xlim(0, 42)\n",
    "        ax.set_xlabel('week_number')\n",
    "    axs[0].set_ylabel('claims')\n",
    "    axs[-1].legend(fancybox=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b270e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_impute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0014d60",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_county():\n",
    "    d = load_imp_tot()\n",
    "    l = []\n",
    "    for (county, week_number), g in d.groupby(['county', 'week_number']):        \n",
    "        l.append({\n",
    "            'county': county,\n",
    "            'fips': g.countyfips.values[0],\n",
    "            'week_number': week_number,\n",
    "            'total_claims': g.total_claims.mean()\n",
    "        })\n",
    "    c = pd.DataFrame(l)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e350f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def avg_weeks(c, start, end):\n",
    "    mask = (start <= c.week_number) & (c.week_number <= end)\n",
    "    cc = c.loc[mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc634ae1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "load_county()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3983d47",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_counties(cc, week_number):\n",
    "    fips = cc.fips\n",
    "    values = cc.total_claims\n",
    "    # endpts = list(np.mgrid[min(values):max(values):4j])\n",
    "    endpts = [15, 30, 45, 60]\n",
    "    colorscale = [\n",
    "        'rgb(239,239,239)',\n",
    "        'rgb(195, 196, 222)',\n",
    "        'rgb(144,148,194)',\n",
    "        'rgb(101,104,168)',\n",
    "        'rgb(65, 53, 132)'\n",
    "    ]\n",
    "    fig = plotly.figure_factory.create_choropleth(\n",
    "        fips=fips, values=values, scope=['Indiana'], show_state_data=True,\n",
    "        colorscale=colorscale, binning_endpoints=endpts, round_legend_values=True,\n",
    "        plot_bgcolor='rgb(229,229,229)',\n",
    "        paper_bgcolor='rgb(229,229,229)',\n",
    "        legend_title=f'Average total claims by county for week {week_number}',\n",
    "        county_outline={'color': 'rgb(255,255,255)', 'width': 0.5},\n",
    "        exponent_format=True,\n",
    "    )\n",
    "    fig.layout.template = None\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805de460",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_county_all():\n",
    "    c = load_county()\n",
    "    week_numbers = [1, 18, 36]\n",
    "    for i, week_number in enumerate(week_numbers):\n",
    "        cc = c.loc[c.week_number == week_number, :]\n",
    "        plot_counties(cc, week_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f7a0ed",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_county_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a55d74f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_extrap(csv_name='3_extrap.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        d = load_imp_tot()\n",
    "        c = load_county()\n",
    "        l = []\n",
    "        for uu_id, g in d.groupby('uu_id'):\n",
    "            g = insert_na_week_number(g, min_week_number=1).reset_index(0, drop=True)\n",
    "            fips = g['countyfips'].values[0]\n",
    "            cc = c.loc[c.fips==fips, :].reset_index(0, drop=True)\n",
    "            g['total_claims'] = g['total_claims'].fillna(cc.total_claims)\n",
    "            l.append(g)\n",
    "        extrap = pd.concat(l, ignore_index=True)\n",
    "        extrap['date'] = extrap['week_number'].apply(week_number_to_date)\n",
    "        extrap.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        extrap = pd.read_csv(csv_name)\n",
    "    return extrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad33f7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "load_extrap()[get_cols(['uu_id', 'week_number', 'total_claims', 'gender'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a56ae0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def replace_na_cols(g):\n",
    "    '''\n",
    "    If a column only has None or zero values, replace that entire columnn with zeros\n",
    "    '''\n",
    "    x = g.copy()\n",
    "    for col in g.columns:\n",
    "        cond1 = g[col].isnull()\n",
    "        cond2 = g[col] == 0\n",
    "        if (cond1 | cond2).all():\n",
    "            x[col] = 0        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258be26",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_iterative(df):\n",
    "    '''\n",
    "    Wrapper fucntion for IterativeImputer for a generic data frame. \n",
    "    Mostly, for testing. We might need need this function\n",
    "    Impute data assuming there are zero columns where all the values are NA\n",
    "    '''\n",
    "    imputer = sklearn.impute.IterativeImputer(random_state=0, min_value=0)\n",
    "    imputed_cols = imputer.fit_transform(df)\n",
    "    df_imputed = pd.DataFrame(imputed_cols, columns=df.columns)\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5855f1a8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def iter_cat(g):\n",
    "    g = replace_na_cols(g)    \n",
    "    for cat in ['edu', 'race', 'gender']:\n",
    "        gg = g.loc[:, COL_MAP[cat] + ['total_claims']]\n",
    "        yield cat, gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c57679",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def print_impute_cat(test_subset, impute_func):\n",
    "    for cat, gg in iter_cat(test_subset):\n",
    "        line = '*'*len(cat)\n",
    "        print(line)\n",
    "        print(cat)\n",
    "        print(line)\n",
    "        print(impute_func(gg).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6bdb56",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print_impute_cat(subset(load_extrap(), 6), impute_iterative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d9e18f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_rowsum(df, target_col='total_claims'):\n",
    "    l = []\n",
    "    for idx, row in df.iterrows():\n",
    "        n_unknowns = row.isna().sum()        \n",
    "        if n_unknowns == 1:\n",
    "            others = row[~row.isna() & (row.index != target_col)]\n",
    "            val = row[target_col] - others.sum()\n",
    "            val = val if val > 0 else 0\n",
    "            row[row.isna()] = val\n",
    "        l.append(row)\n",
    "    df = pd.DataFrame(l).reset_index(0, drop=True)\n",
    "    \n",
    "    l = []\n",
    "    for idx, row in df.iterrows():\n",
    "        n_unknowns = row.isna().sum()        \n",
    "        \n",
    "        weights = {}\n",
    "        for col in row[row.isna()].index:\n",
    "            weights[col] = df[col].mean()\n",
    "        weights = {k:v/sum(weights.values()) for k, v in weights.items()}       \n",
    "        \n",
    "        if n_unknowns > 1:            \n",
    "            others = row[~row.isna() & (row.index != target_col)]\n",
    "            row[row.isna()] = row[row.isna()].index.map(weights)*(row[target_col] - others.sum())            \n",
    "        l.append(row)\n",
    "        \n",
    "    df_imputed = pd.DataFrame(l).reset_index(0, drop=True)\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927e174",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print_impute_cat(subset(load_extrap(), 6), impute_rowsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a88450",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_all(df):\n",
    "    x = df.copy().reset_index(0, drop=True)\n",
    "    for cat, gg in iter_cat(df):\n",
    "        df_imputed = impute_rowsum(gg)\n",
    "        df_imputed = df_imputed.drop('total_claims', axis=1)\n",
    "        x[COL_MAP[cat]] = df_imputed\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ebb3a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_imp_feature(csv_name='4_imp_feature.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        imp_tot = load_extrap()\n",
    "        imp = imp_tot.groupby('uu_id').apply(impute_all).reset_index(0, drop=True)\n",
    "        imp['date'] = imp['week_number'].apply(week_number_to_date)\n",
    "        imp.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        imp = pd.read_csv(csv_name)\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b53378",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "load_imp_feature().to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f87342",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_logistic(g, ycol):\n",
    "    g = g[[ycol, 'week_number', 'total_claims']]\n",
    "    xcols = ['week_number', 'total_claims']\n",
    "    ycols = [ycol]\n",
    "    \n",
    "    mask_train = ~g[ycol].isnull()\n",
    "    x_train, x_test = g.loc[mask_train, xcols], g.loc[~mask_train, xcols]\n",
    "    y_train, y_test = g.loc[mask_train, ycols], g.loc[~mask_train, ycols]\n",
    "    \n",
    "    if y_train.shape[0] == 0:\n",
    "        g[ycol] = None\n",
    "        return g[ycol]\n",
    "    \n",
    "    classes = y_train[ycol].unique()\n",
    "    if len(classes) == 1:\n",
    "        yhat = [classes[0]]\n",
    "    else:\n",
    "        model = sklearn.linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=10000).fit(x_train, y_train.values.ravel())\n",
    "        yhat = model.predict(x_test)\n",
    "    g.loc[~mask_train, ycols] = yhat\n",
    "    return g[ycol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b568a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def impute_industry(g, max_week_number=37):\n",
    "    g = g.loc[g.week_number <= max_week_number, :]\n",
    "    x = g.copy()\n",
    "    for colname in COL_MAP['industry']:\n",
    "        x[colname] = impute_logistic(g, colname)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca81b7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_imp_industry(csv_name='5_imp_industry.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        d = load_imp_feature()\n",
    "        d = d.groupby('uu_id').apply(impute_industry).reset_index(0, drop=True)\n",
    "        d.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        d = pd.read_csv(csv_name)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc4f33",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "load_imp_industry().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65183304",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def feature_engineer(d):\n",
    "    d['gender_male_ratio'] = d['gender_male'] / d['total_claims']\n",
    "    d['edu_post_hs_ratio'] = d['edu_post_hs'] / d['total_claims']\n",
    "    d['race_white_ratio'] = d['race_white'] / d['total_claims']\n",
    "    d['race_black_ratio'] = d['race_black'] / d['total_claims']\n",
    "    d = d.drop(get_cols(['gender', 'edu', 'race']), axis=1)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0a2e8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_featured(csv_name='6_featured.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        d = load_imp_industry()\n",
    "        d = feature_engineer(d)\n",
    "        d.to_csv(csv_name, index=False)\n",
    "    else:\n",
    "        d = pd.read_csv(csv_name)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_featured().to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb155fe",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a6ff09",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def arimax(y, order, seasonal_order, exog=None):\n",
    "    model = sm.tsa.statespace.SARIMAX(y, exog=exog, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "    results = model.fit(maxiter=300, disp=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a510658",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_best_params(y, exog=None, period=0, steps=2):\n",
    "    r1 = r2 = r3 = range(steps)\n",
    "    pdq = list(itertools.product(r1, r2, r3))    \n",
    "    if period:\n",
    "        seasonal_pdq = [(x[0], x[1], x[2], period) for x in list(itertools.product(r1, r2, r3))]\n",
    "    else:\n",
    "        seasonal_pdq = [(0, 0, 0, 0)]\n",
    "    aic_min = np.inf\n",
    "    for order in pdq:\n",
    "        for seasonal_order in seasonal_pdq:\n",
    "            results = arimax(y, order, seasonal_order, exog=exog)\n",
    "            if results.aic < aic_min:\n",
    "                aic_min = results.aic\n",
    "                best_params = [order, seasonal_order, results.aic]            \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae035dd7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def predict(g, exog=False, ylabel='total_claims', target_week_number=43):\n",
    "    g = g.set_index('date')\n",
    "    g.index = pd.DatetimeIndex(g.index).to_period('W')\n",
    "    y = g[ylabel].astype(np.float64)\n",
    "    x = g[['edu_post_hs_ratio', 'gender_male_ratio', 'race_white_ratio', 'race_black_ratio']]\n",
    "    if exog:\n",
    "        best_params = get_best_params(y, exog=x)\n",
    "    else:\n",
    "        best_params = get_best_params(y)\n",
    "    best_results = arimax(y, best_params[0], best_params[1])    \n",
    "    pred = best_results.get_prediction(start=week_number_to_date(target_week_number - 10), end=week_number_to_date(target_week_number), dynamic=False)\n",
    "    \n",
    "    x = g.join(pred.predicted_mean, on=g.index, how='outer')\n",
    "    x['date'] = x.key_0\n",
    "    ci = pred.conf_int()\n",
    "    x['ci_lower'] = ci.iloc[:, 0]\n",
    "    x['ci_upper'] = ci.iloc[:, 1]\n",
    "    x['uu_id'] = g['uu_id'].values[0]\n",
    "    x['predicted'] = x['predicted_mean']\n",
    "    x = x.reset_index(0, drop=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a251b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def predict_all(d, ylabel, csv_name, exog=False):\n",
    "    l = []\n",
    "    for i, (uu_id, g) in enumerate(d.groupby('uu_id')):    \n",
    "        if i % 100 == 0:\n",
    "            print(f'processed {i} UUIDs')\n",
    "        predicted = predict(g, ylabel=ylabel, exog=exog)\n",
    "        l.append(predicted)        \n",
    "    df = pd.concat(l, ignore_index=True)\n",
    "    df.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceff4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('results_arima.csv'):\n",
    "    predict_all(load_featured(), 'total_claims', 'results_arima.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7dd25",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('results_arimax.csv'):\n",
    "    predict_all(load_featured(), 'total_claims', 'results_arimax.csv', exog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ff25d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_arima(n=6):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=n, figsize=(3*n, 3))\n",
    "    res_arima = pd.read_csv('results_arima.csv')\n",
    "    res_arimax = pd.read_csv('results_arimax.csv')\n",
    "    raw = load_featured()\n",
    "    for i in range(n):\n",
    "        ax = axs[i]\n",
    "        rraw = subset(raw, i)\n",
    "        rres_arima = subset(res_arima, i)\n",
    "        rres_arimax = subset(res_arimax, i)\n",
    "        ax.plot(rraw.week_number, rraw.total_claims, 'o-', label='raw')\n",
    "        ax.plot(rres_arima.week_number, rres_arima.predicted, 'o-', label='arima')\n",
    "        ax.plot(rres_arimax.week_number, rres_arimax.predicted, 'o-', label='arimax')\n",
    "        ax.set_xlim(0, 42)\n",
    "        ax.set_xlabel('week_number')\n",
    "        ax.set_ylim(0, None)\n",
    "    axs[0].set_ylabel('claims')\n",
    "    axs[-1].legend(fancybox=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faec71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_arima()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95349caf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "convert_to_submission('results_arima.csv', week_number_to_submit=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f6065",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_train_test(g, split_week_number=30):\n",
    "    xcols = ['edu_post_hs_ratio', 'gender_male_ratio', 'race_white_ratio', 'race_black_ratio', 'week_number']\n",
    "    ycols = ['total_claims']    \n",
    "    mask_train = g.week_number <= split_week_number\n",
    "    mask_test = ~mask_train\n",
    "    \n",
    "    x_train, x_test = g.loc[mask_train, xcols], g.loc[mask_test, xcols]\n",
    "    y_train, y_test = g.loc[mask_train, ycols], g.loc[mask_test, ycols]\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f2114",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_rf(g, split_week_number=30):\n",
    "    x_train, x_test, y_train, y_test = get_train_test(g, split_week_number=split_week_number)\n",
    "    rf = sklearn.ensemble.RandomForestRegressor(n_estimators=100, random_state=0).fit(x_train, y_train.values.ravel())\n",
    "    yhat = rf.predict(pd.concat([x_train, x_test]))\n",
    "    return x_train, x_test, y_train, y_test, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc456357",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_rf(d):\n",
    "    fig, axs = plt.subplots(ncols=6, figsize=(18, 3), sharey=True)\n",
    "    for i in range(6):\n",
    "        ax = axs[i]\n",
    "        dd = subset(d, i)\n",
    "        \n",
    "        x_train, x_test, y_train, y_test, yhat = run_rf(dd)\n",
    "        ax.plot(x_train.week_number, y_train, 'o-', label='original')\n",
    "        ax.plot(dd.week_number, yhat, 'o-', label='predict')\n",
    "        ax.set_xlabel('week_number')\n",
    "        ax.set_title(f'uu_id: {i}')\n",
    "        ax.set_xlim(0, 42)\n",
    "            \n",
    "    axs[-1].legend(frameon=False)\n",
    "    axs[0].set_ylabel('claims')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a46340f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_rf(load_featured())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ad204",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def rf_industry(g):\n",
    "    uu_id = g.uu_id.values[0]\n",
    "    gg = g[COL_MAP['industry'] + ['week_number', 'total_claims']]    \n",
    "    gg = gg.dropna()\n",
    "    gg = pd.get_dummies(gg)\n",
    "        \n",
    "    if gg.shape[0] == 0:\n",
    "        print(g.uu_id.values[0])\n",
    "        mean = g.total_claims.mean()\n",
    "        return pd.DataFrame([{'uu_id': uu_id, 'week_number': 38, 'total_claims': mean, 'predicted': mean}])\n",
    "    x = gg.drop(['total_claims'], axis=1)    \n",
    "    y = gg['total_claims']    \n",
    "    max_avail_week_number = int(x.week_number.max())\n",
    "    rf = sklearn.ensemble.RandomForestRegressor(n_estimators=100, random_state=0).fit(x, y.values.ravel())\n",
    "    last = x.loc[x.week_number == max_avail_week_number, :].copy()\n",
    "    last['week_number'] = max_avail_week_number + 1\n",
    "    x_test = pd.concat([x, last], ignore_index=True)\n",
    "    x_test['predicted'] = rf.predict(x_test)\n",
    "    result = x_test.copy()\n",
    "    result['total_claims'] = y.reset_index(0, drop=True)\n",
    "    result['uu_id'] = uu_id\n",
    "    return result[['uu_id', 'week_number', 'total_claims', 'predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac759d2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_industry(d):\n",
    "    fig, axs = plt.subplots(ncols=6, figsize=(18, 3), sharey=True)\n",
    "    for i in range(6):\n",
    "        ax = axs[i]\n",
    "        dd = subset(d, i)\n",
    "        result = rf_industry(dd)\n",
    "        ax.plot(result.week_number, result.total_claims, 'o-', label='original')\n",
    "        ax.plot(result.week_number, result.predicted, 'o-', label='predict')\n",
    "        ax.set_xlabel('week_number')\n",
    "        ax.set_title(f'uu_id: {i}')\n",
    "        ax.set_xlim(0, 42)\n",
    "            \n",
    "    axs[-1].legend(frameon=False)\n",
    "    axs[0].set_ylabel('claims')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1ade6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_industry(load_featured())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ce3d9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_rf_all(d, csv_name='results_rf.csv'):\n",
    "    if not os.path.isfile(csv_name):\n",
    "        result_rf = d.groupby('uu_id').apply(rf_industry).reset_index(0, drop=True)\n",
    "        result_rf.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe9c6ba",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "run_rf_all(load_featured())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abfee83",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_train_test(g):    \n",
    "    xcols = ['edu_post_hs_ratio', 'gender_male_ratio', 'race_white_ratio', 'race_black_ratio', 'week_number']\n",
    "    ycols = ['total_claims']\n",
    "    mask_train = g.week_number <= 30\n",
    "    mask_test = ~mask_train\n",
    "    g_train = g.loc[mask_train, :]\n",
    "    g_test = g.loc[mask_test, :]\n",
    "    \n",
    "    x_train = g_train[xcols]\n",
    "    y_train = g_train[ycols]\n",
    "    x_test = g_test[xcols]\n",
    "    y_test = g_test[ycols]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fbc2d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_xgb_old(g, params={'n_estimators': 1000}):\n",
    "    uu_id = g.uu_id.values[0]\n",
    "    x_train, y_train, x_test, y_test = get_train_test(g)\n",
    "    reg = xgb.XGBRegressor(objective='reg:squarederror', **params)\n",
    "    reg.fit(x_train, y_train, verbose=True)\n",
    "    yhat = reg.predict(x_test)\n",
    "    x_test['predicted'] = yhat\n",
    "    x_test['uu_id'] = uu_id\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6362aec7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def optimize_xgb(g):\n",
    "    uu_id = g.uu_id.values[0]\n",
    "    x, y, x_test = get_train_test(g)\n",
    "    # params = {\n",
    "    #     'min_child_weight': [1, 5, 10],\n",
    "    #     'gamma': [0.3, 0.5, 1.0, 1.5, 2.0, 5.0],\n",
    "    #     'subsample': [0.6, 0.8, 1.0],\n",
    "    #     'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    #     'max_depth': [2, 3, 4, 5],\n",
    "    #     'n_estimators': [300, 600, 1000],\n",
    "    #     'learning_rate': [0.001, 0.01, 0.1]\n",
    "    # }\n",
    "    params = {\n",
    "        'min_child_weight': [1],\n",
    "        'gamma': [0.3],\n",
    "        'subsample': [0.6, 0.8],\n",
    "        'colsample_bytree': [0.6, 0.8],\n",
    "        'max_depth': [3],\n",
    "        'n_estimators': [600, 1000]        \n",
    "    }\n",
    "    reg = xgb.XGBRegressor(nthread=-1, objective='reg:squarederror')\n",
    "    grid = sklearn.model_selection.GridSearchCV(reg, params)\n",
    "    grid.fit(x, y)\n",
    "    yhat = grid.best_estimator_.predict(x_test)\n",
    "    x_test['predicted'] = yhat\n",
    "    x_test['uu_id'] = uu_id\n",
    "    return x_test, grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b310a4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_xgb(d, n=6):    \n",
    "    fig, axs = plt.subplots(ncols=n, figsize=(18, 3), sharey=True)\n",
    "    for i in range(n):\n",
    "        ax = axs[i]\n",
    "        g = subset(d, i)\n",
    "        pred = run_xgb_old(g)\n",
    "        # pred, best_score, best_params = optimize_xgb(g)\n",
    "        # print(i)\n",
    "        # print(f'best score: {best_score}')\n",
    "        # print('best_param: ', best_params)\n",
    "        ax.plot(g.week_number, g.total_claims, 'o-', label='raw')\n",
    "        ax.plot(pred.week_number, pred.predicted, 'o-', label='xgboost')\n",
    "        ax.set_xlim(0, 42)\n",
    "        ax.set_xlabel('week_number')\n",
    "    axs[0].set_ylabel('claims')\n",
    "    axs[-1].legend(fancybox=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b27548",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plot_xgb(load_featured())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b338bd89",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess_xgb(d):\n",
    "    d = d[['total_claims', 'uu_id', 'average_wage', 'week_number', 'edu_post_hs_ratio', 'gender_male_ratio', 'race_white_ratio', 'race_black_ratio']].copy()\n",
    "    # d = get_dummies(d, COL_MAP['industry'])\n",
    "    d['date'] = d['week_number'].apply(week_number_to_date)\n",
    "    d['month'] = d['date'].dt.month\n",
    "    d['quarter'] = d['date'].dt.quarter\n",
    "    nlags = 3\n",
    "    d['mean_month'] = d.groupby('month')['total_claims'].transform(lambda x: float(x.dropna().mean()))\n",
    "    d['mean_quarter'] = d.groupby('quarter')['total_claims'].transform(lambda x: float(x.dropna().mean())) \n",
    "    \n",
    "    for lag in range(1, nlags + 1):        \n",
    "        d[f'shift_{lag}'] = d.groupby('uu_id')['total_claims'].transform(lambda x: x.shift(lag))\n",
    "    \n",
    "    d = d.drop(['date'], axis=1)    \n",
    "    encoder = sklearn.preprocessing.LabelEncoder()\n",
    "    d['uu_id'] = encoder.fit_transform(d['uu_id'].astype(str))\n",
    "    d = d.dropna()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32f41a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "preprocess_xgb(load_featured())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6a227",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_train_test_xgb(g):\n",
    "    mask_train = g.week_number <= 30\n",
    "    mask_test = ~mask_train\n",
    "    x_cols = g.columns.difference(['total_claims'])\n",
    "    y_cols = ['total_claims']\n",
    "    x_train = g.loc[mask_train, x_cols]\n",
    "    y_train = g.loc[mask_train, y_cols]\n",
    "    x_test = g.loc[mask_test, x_cols]\n",
    "    y_test = g.loc[mask_test, y_cols]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1605f519",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_xgb(g, params={'n_estimators': 1000}):\n",
    "    x_train, y_train, x_test, y_test = get_train_test_xgb(g)\n",
    "    reg = xgb.XGBRegressor(objective='reg:squarederror', **params)\n",
    "    reg.fit(x_train, y_train, verbose=True)\n",
    "    yhat = reg.predict(x_test)\n",
    "    x_test['predicted'] = yhat\n",
    "    x_test['total_claims'] = y_test\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86065b73",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_xgb(n=6):    \n",
    "    pp = preprocess_xgb(load_featured())\n",
    "    res = run_xgb(pp)\n",
    "    \n",
    "    ncols = 6\n",
    "    nrows = int(np.ceil(n/ncols))\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(3*ncols, 3*nrows), sharex=True)\n",
    "    for i in range(n):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        idx_row = int(i / ncols)\n",
    "        idx_col = i % ncols\n",
    "        if nrows == 1:\n",
    "            ax = axs[idx_col]\n",
    "        else:\n",
    "            ax = axs[idx_row, idx_col]\n",
    "        ppp = pp.loc[pp.uu_id == pp.uu_id.unique()[i], :]\n",
    "        rres = res.loc[res.uu_id == res.uu_id.unique()[i], :]\n",
    "        ax.plot(ppp.week_number, ppp.total_claims, 'o-', label='raw')\n",
    "        ax.plot(rres.week_number, rres.predicted, 'o-', label='xgboost')\n",
    "        ax.set_xlim(0, 42)\n",
    "        ax.set_xlabel('week_number')\n",
    "        if idx_col == 0:\n",
    "            ax.set_ylabel('claims')\n",
    "        if idx_col == ncols - 1:\n",
    "            ax.legend(fancybox=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6ebe0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plot_xgb(n=24)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
